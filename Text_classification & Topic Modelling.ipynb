{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4fa2c72",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "\n",
    "FashionKart allows consumers to buy latest products from e-commerce platforms. Customers can leave reviews of products and experience to help other users make their purchase choices.\n",
    " \n",
    "Given the dataset of product reviews and recommendation status, build a text classification model that can correctly identify the users who will recommend the product in the future. Also provide key topics/themes emerging from the customer reviews along with visualisation charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffdd10",
   "metadata": {},
   "source": [
    "**Review:** Customer review for the product\n",
    "\n",
    "**Recommendation:** Customer's recommendation for the product "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f017599",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "1. **[Import Libraries](#lib)**\n",
    "2. **[Load the Data](#data)**\n",
    "3. **[Data Exploration](#eda)**\n",
    "4. **[Data Preperation](#prep)**\n",
    "5. **[Data Split](#split)**\n",
    "6. **[Machine Learning Modeling](#model)**\n",
    "    - 6.1 - **[Count vectorizer](#cv)**\n",
    "    - 6.2 - **[TF-IDF](#tfidf)**\n",
    "7. **[Topic Modelling ](#topic)**\n",
    "    - 7.1 - **[Topic Visualization](#vis)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa510728",
   "metadata": {},
   "source": [
    "<a id=\"lib\"></a>\n",
    "### Step 1 : Load required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4b840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b594bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: numexpr in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.3)\n",
      "Requirement already satisfied: gensim in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.21.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (61.2.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.0.post1)\n",
      "Requirement already satisfied: funcy in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.17)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.4.3)\n",
      "Requirement already satisfied: future in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (0.29.28)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from scikit-learn->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aravinddudipala\\anaconda3\\lib\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6680703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AravindDudipala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AravindDudipala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\AravindDudipala\\anaconda3\\lib\\site-packages\\seaborn\\rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "C:\\Users\\AravindDudipala\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "#import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import umap\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "     \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471839e",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "### Step 2 : Load the input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd2bb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Recommend\n",
       "0  Absolutely wonderful - silky and sexy and comf...          1\n",
       "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
       "2  I had such high hopes for this dress and reall...          0\n",
       "3  I love, love, love this jumpsuit. it's fun, fl...          1\n",
       "4  This shirt is very flattering to all due to th...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the input data\n",
    "input_data = pd.read_csv('dataset.csv')\n",
    "#scan the dataframe\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b380b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Review     22641 non-null  object\n",
      " 1   Recommend  23486 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 367.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#convert the object datatype type to string\n",
    "input_data.info()\n",
    "input_data['Review']=input_data['Review'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f678b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the size of the dataframe\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb4c4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19314\n",
       "0     4172\n",
       "Name: Recommend, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the target class distribution in the dataset\n",
    "input_data['Recommend'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbd901",
   "metadata": {},
   "source": [
    "As we can see there are around 23K+ reviews in the dataset. Each review has a corresponding recommendation value and there are more recommended products compared to non-recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8618ae4",
   "metadata": {},
   "source": [
    "<a id=\"eda\"></a>\n",
    "### Step 3 : Explore the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd3a29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check for the target class counts \n",
    "label_dist = input_data['Recommend'].value_counts().to_dict()\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = plt.bar(label_dist.keys(), label_dist.values(), width=0.25)\n",
    "plt.xticks([0,1])\n",
    "plt.xlabel(\"Recommendation\")\n",
    "plt.ylabel(\"Review Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dca6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review       0\n",
      "Recommend    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for any empty rows \n",
    "print(input_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4dc28d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any duplicate reviews \n",
    "len(input_data['Review'])-len(input_data['Review'].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1f62e",
   "metadata": {},
   "source": [
    "As we can observe there are 851 reviews which seem to be duplicate values. We will drop these from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a5a882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22635, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the repeated reviews \n",
    "input_data=input_data.drop_duplicates(subset='Review', keep=\"last\")\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9df5a",
   "metadata": {},
   "source": [
    "We can now check the size of each review to establish if there is any relation between the recommendation and length of the reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb85de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for the length of reviews \n",
    "input_data['length']=input_data['Review'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c936f159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Recommend</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10072</th>\n",
       "      <td>Love this top! i bought it in 2 colors; it's a...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19589</th>\n",
       "      <td>This top is very pretty and looks so good with...</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19585</th>\n",
       "      <td>These pants are beautiful. the color is a nice...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17815</th>\n",
       "      <td>I didn't pay much attention to this shirt on t...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15179</th>\n",
       "      <td>Other than the color (i got the rose color), w...</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20734</th>\n",
       "      <td>I'm so excited that retailer is bringing back ...</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>Love this top!!!! it is just gorgeous and fits...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21293</th>\n",
       "      <td>Love these pants- they are so soft and comfort...</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12766</th>\n",
       "      <td>I am a 5'10\" size 4 (or 28 long - i need a 33-...</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12428</th>\n",
       "      <td>I love this top (so cute and comfy!), but i wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Recommend  length\n",
       "10072  Love this top! i bought it in 2 colors; it's a...          1      20\n",
       "19589  This top is very pretty and looks so good with...          1     106\n",
       "19585  These pants are beautiful. the color is a nice...          1      95\n",
       "17815  I didn't pay much attention to this shirt on t...          1      88\n",
       "15179  Other than the color (i got the rose color), w...          1      78\n",
       "20734  I'm so excited that retailer is bringing back ...          1      82\n",
       "6588   Love this top!!!! it is just gorgeous and fits...          1      10\n",
       "21293  Love these pants- they are so soft and comfort...          1      44\n",
       "12766  I am a 5'10\" size 4 (or 28 long - i need a 33-...          1      86\n",
       "12428  I love this top (so cute and comfy!), but i wo...          0      61"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the newly added column in the dataframe \n",
    "input_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989ae86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "#avg. length for recommended and non recommended review \n",
    "print(round(input_data[input_data['Recommend']== 1 ]['length'].mean()))\n",
    "print(round(input_data[input_data['Recommend']== 0]['length'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6c641",
   "metadata": {},
   "source": [
    "Seems like there isn't much of a difference between size of the customer review in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc5cd4",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "### Step 4 : Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09e77d",
   "metadata": {},
   "source": [
    "Since the reviews are raw texts and contains multiple symbols, punctuations , hastags which might not be very useful for the modeling . \n",
    "We will use a helper function to clean the text and prepare it for modeling purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83bb1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to remove stopwords\n",
    "input_data[\"Review_new\"]=input_data[\"Review\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (STOPWORDS)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ad736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for review cleaning \n",
    "def text_clean(review):\n",
    "    #lowercase the review\n",
    "    review=review.lower()\n",
    "    #remove punctuation \n",
    "    review = re.sub('[()!?]', ' ', review)\n",
    "    review = re.sub('\\[.*?\\]',' ', review)\n",
    "    #remove non alphanumeric occurences\n",
    "    review = re.sub(\"[^a-z0-9]\",\" \", review)\n",
    "    #remove the @mention\n",
    "    review = re.sub(\"@[A-Za-z0-9_]+\",\"\", review)\n",
    "    #remove the hastags\n",
    "    review = re.sub(\"#[A-Za-z0-9_]+\",\"\", review)\n",
    "    #remove any links \n",
    "    review = re.sub(r\"http\\S+\", \"\", review)\n",
    "    review = re.sub(r\"www.\\S+\", \"\", review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b98afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function on the review column \n",
    "input_data['clean_review'] = input_data['Review_new'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec41234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>I just received these jeans and the fit it goo...</td>\n",
       "      <td>i received jeans fit good  smell like moth bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21040</th>\n",
       "      <td>When i wore this the two times i did, i got a ...</td>\n",
       "      <td>when wore two times did  got ton compliments  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18480</th>\n",
       "      <td>And the bottom looks like a tutu. first, i hav...</td>\n",
       "      <td>and bottom looks like tutu  first  high tolera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>I really like this top. while it looks somewha...</td>\n",
       "      <td>i really like top  looks somewhat like t shirt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>I agree with the other reviews - runs small. w...</td>\n",
       "      <td>i agree reviews   runs small  would perfect ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>This is a stylish blouse with classic features...</td>\n",
       "      <td>this stylish blouse classic features well quir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>This dress runs large so i sized down. when it...</td>\n",
       "      <td>this dress runs large sized down  arrived look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21431</th>\n",
       "      <td>Cute shirt but it is very hard to wrap my head...</td>\n",
       "      <td>cute shirt hard wrap head around xxs  sizing r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19840</th>\n",
       "      <td>I was so excited to wear this shirt, even afte...</td>\n",
       "      <td>i excited wear shirt  even reading review curl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14006</th>\n",
       "      <td>I had to order on line -- so popular that my s...</td>\n",
       "      <td>i order line    popular store sold out  ordere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  \\\n",
       "9956   I just received these jeans and the fit it goo...   \n",
       "21040  When i wore this the two times i did, i got a ...   \n",
       "18480  And the bottom looks like a tutu. first, i hav...   \n",
       "7930   I really like this top. while it looks somewha...   \n",
       "1977   I agree with the other reviews - runs small. w...   \n",
       "11928  This is a stylish blouse with classic features...   \n",
       "2025   This dress runs large so i sized down. when it...   \n",
       "21431  Cute shirt but it is very hard to wrap my head...   \n",
       "19840  I was so excited to wear this shirt, even afte...   \n",
       "14006  I had to order on line -- so popular that my s...   \n",
       "\n",
       "                                            clean_review  \n",
       "9956   i received jeans fit good  smell like moth bal...  \n",
       "21040  when wore two times did  got ton compliments  ...  \n",
       "18480  and bottom looks like tutu  first  high tolera...  \n",
       "7930   i really like top  looks somewhat like t shirt...  \n",
       "1977   i agree reviews   runs small  would perfect ac...  \n",
       "11928  this stylish blouse classic features well quir...  \n",
       "2025   this dress runs large sized down  arrived look...  \n",
       "21431  cute shirt hard wrap head around xxs  sizing r...  \n",
       "19840  i excited wear shirt  even reading review curl...  \n",
       "14006  i order line    popular store sold out  ordere...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate if the reviews are clean\n",
    "input_data[['Review','clean_review']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c35c2",
   "metadata": {},
   "source": [
    "We can now observe that each review looks much cleaner and neat post the data cleansing prcoess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6db154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alculate updated length after removing the stopwords and cleaning review\n",
    "input_data['new_length']=input_data['clean_review'].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "756b73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "#avg. length of the review for recommended and non-recommended labels \n",
    "print(round(input_data[input_data['Recommend']== 1]['new_length'].mean()))\n",
    "print(round(input_data[input_data['Recommend']== 0]['new_length'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322f1b2",
   "metadata": {},
   "source": [
    "Post the data cleaning, the avg. length of the review becomes the same "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a31bc3",
   "metadata": {},
   "source": [
    "<a id=\"split\"></a>\n",
    "### Step 5 : Data split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fdded",
   "metadata": {},
   "source": [
    "Now we split the 23K+ data into training and test dataset. One thing to note is to split the data based on target class to maintain the class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "394e49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Classifier\n",
    "#split the data into training and test set with balanced split based on target class\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data[\"clean_review\"],\n",
    "                                                    input_data[\"Recommend\"],test_size=0.3,\n",
    "                                                    stratify=input_data['Recommend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f16f1a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15844 6791\n"
     ]
    }
   ],
   "source": [
    "#check the shape of train and test data \n",
    "print(X_train.shape[0],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3697a792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    12974\n",
      "0     2870\n",
      "Name: Recommend, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check the class balance in train data \n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "125e74de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5561\n",
      "0    1230\n",
      "Name: Recommend, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check the target class balance in test data \n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af9940",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "### Step 6  : ML Modeling and Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6f02a",
   "metadata": {},
   "source": [
    "After splitting the data , we move on to the modelling part. Given we are doing text classification, we will convert the text data using two approaches :\n",
    "1. Count Vectoriser \n",
    "2. TF-IDF \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa911f1",
   "metadata": {},
   "source": [
    "<a id=\"cv\"></a>\n",
    "#### Using Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37043714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a list of models to be trained and tested\n",
    "modelclasses = [\n",
    "    [\"Logistic Regression\", LogisticRegression],\n",
    "    [\"MNB\", MultinomialNB],\n",
    "    [\"Random Forest\", RandomForestClassifier]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2fb0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the count vectoriser to convert the text data to numerical form\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "#create an empty dataframe to log performance of the model based on score and auc\n",
    "results = pd.DataFrame(columns = ['modelname','score','auc'])\n",
    "\n",
    "for modelname, Model in modelclasses:\n",
    "    model = Model()\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    score = np.round(model.score(X_test_vec, y_test),2)\n",
    "    auc=np.round(roc_auc_score(y_test, model.predict_proba(X_test_vec)[:, 1]),2)\n",
    "    results = results.append({'modelname' : modelname, 'score' : score,'auc':auc},\n",
    "        ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9d9475b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNB</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             modelname  score   auc\n",
       "0  Logistic Regression   0.88  0.91\n",
       "1                  MNB   0.89  0.92\n",
       "2        Random Forest   0.85  0.91"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model performance \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e6204",
   "metadata": {},
   "source": [
    "As we can observe , the Multinomial Naive Baysian performs the best out of all the models using count vectoriser "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf8f5a3",
   "metadata": {},
   "source": [
    "<a id=\"tfidf\"></a>\n",
    "#### Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddbd1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the tf-idf vectoriser to convert the text data to numerical form\n",
    "vectorizertfidf = TfidfVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "X_train_vec = vectorizertfidf.fit_transform(X_train)\n",
    "X_test_vec = vectorizertfidf.transform(X_test)\n",
    "results_tf = pd.DataFrame(columns = ['modelname','score','auc'])\n",
    "for modelname, Model in modelclasses:\n",
    "    model = Model()\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    score = np.round(model.score(X_test_vec, y_test),2)\n",
    "    auc=np.round(roc_auc_score(y_test, model.predict_proba(X_test_vec)[:, 1]),2)\n",
    "    results_tf = results_tf.append({'modelname' : modelname, 'score' : score,'auc':auc},\n",
    "        ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8384ef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNB</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             modelname  score   auc\n",
       "0  Logistic Regression   0.88  0.93\n",
       "1                  MNB   0.82  0.90\n",
       "2        Random Forest   0.85  0.91"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model comparison \n",
    "results_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a8420",
   "metadata": {},
   "source": [
    "Using the tf-idf vectoriser, we observe Logistic Regression outperforming the other models in terms of accuracy and auc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84a7ac",
   "metadata": {},
   "source": [
    "<a id=\"topic\"></a>\n",
    "## Step 7 : Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "467980de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add additonal data clearning\n",
    "def topic_clean(review):\n",
    "        #remove numeric & special characters occurences\n",
    "        review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "        review = re.sub(r's+', ' ', review)\n",
    "        return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f7caa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function on the review column \n",
    "input_data['clean_review'] = input_data['clean_review'].apply(topic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52b2cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract every unique term from the reviews \n",
    "review_terms = pd.Series(input_data['clean_review']).apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5548bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the disctioanry consisting index and unique term\n",
    "dictionary = corpora.Dictionary(review_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "842dcf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preapre the DTM(Document Term Matrix) from the term dictionary \n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in review_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6871cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model for topic extraction \n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "lda_model = LDA(corpus=doc_term_matrix,\n",
    "                id2word=dictionary,\n",
    "                num_topics=10, \n",
    "                chunksize=500,\n",
    "                passes=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a6406c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.042*\"great\" + 0.038*\"love\" + 0.029*\"top\" + 0.027*\"hirt\" + 0.026*\"color\" + 0.024*\"fit\" + 0.019*\"i\" + 0.019*\"ual\" + 0.018*\"perfect\" + 0.018*\"oft\"'),\n",
       " (1,\n",
       "  '0.045*\"wa\" + 0.033*\"e\" + 0.025*\"purcha\" + 0.024*\"ed\" + 0.020*\"ion\" + 0.019*\"hed\" + 0.018*\"one\" + 0.017*\"h\" + 0.015*\"t\" + 0.013*\"ye\"'),\n",
       " (2,\n",
       "  '0.031*\"top\" + 0.023*\"like\" + 0.022*\"look\" + 0.020*\"fabric\" + 0.018*\"de\" + 0.016*\"e\" + 0.014*\"o\" + 0.013*\"back\" + 0.012*\"ign\" + 0.012*\"hirt\"'),\n",
       " (3,\n",
       "  '0.121*\"color\" + 0.076*\"blue\" + 0.037*\"green\" + 0.033*\"grey\" + 0.025*\"gray\" + 0.022*\"pink\" + 0.022*\"kin\" + 0.020*\"navy\" + 0.019*\"orange\" + 0.017*\"vibrant\"'),\n",
       " (4,\n",
       "  '0.023*\"tic\" + 0.023*\"clo\" + 0.017*\"h\" + 0.016*\"ela\" + 0.014*\"in\" + 0.013*\"pocket\" + 0.013*\"button\" + 0.012*\"et\" + 0.011*\"ide\" + 0.011*\"t\"'),\n",
       " (5,\n",
       "  '0.228*\"dre\" + 0.025*\"ea\" + 0.021*\"y\" + 0.020*\"flattering\" + 0.019*\"fit\" + 0.018*\"thi\" + 0.018*\"perfect\" + 0.017*\"love\" + 0.015*\"wear\" + 0.013*\"kirt\"'),\n",
       " (6,\n",
       "  '0.042*\"i\" + 0.038*\"ize\" + 0.025*\"t\" + 0.024*\"fit\" + 0.023*\"m\" + 0.022*\"mall\" + 0.014*\"u\" + 0.013*\"ordered\" + 0.013*\"would\" + 0.013*\"large\"'),\n",
       " (7,\n",
       "  '0.034*\"e\" + 0.030*\"pant\" + 0.026*\"i\" + 0.026*\"jean\" + 0.021*\"love\" + 0.020*\"t\" + 0.019*\"fit\" + 0.017*\"the\" + 0.017*\"great\" + 0.016*\"pair\"'),\n",
       " (8,\n",
       "  '0.066*\"weater\" + 0.036*\"love\" + 0.028*\"it\" + 0.028*\"i\" + 0.025*\"jacket\" + 0.024*\"wear\" + 0.023*\"compliment\" + 0.021*\"ab\" + 0.019*\"olutely\" + 0.018*\"many\"'),\n",
       " (9,\n",
       "  '0.037*\"i\" + 0.036*\"t\" + 0.022*\"on\" + 0.021*\"tore\" + 0.020*\"it\" + 0.015*\"online\" + 0.014*\"di\" + 0.013*\"tried\" + 0.013*\"price\" + 0.013*\"ale\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the top 10 topics \n",
    "lda_model.print_topics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357a144",
   "metadata": {},
   "source": [
    "<a id=\"vis\"></a>\n",
    "#### Topic Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23780a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el308830801681891689247050517\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el308830801681891689247050517_data = {\"mdsDat\": {\"x\": [-0.14636254482541072, -0.13523859805359528, -0.00448536689752328, -0.12921442669573524, -0.13885604573751292, -0.14147150390964008, -0.04702590985712658, 0.20643327033696923, 0.2237866934492468, 0.3124344321903282], \"y\": [-0.08021165762849022, -0.0065526394095380205, -0.13610551663418646, -0.022651231458296367, 0.11984512323132206, 0.11911947227582109, 0.05901935252681001, -0.19052726334489942, -0.18387693376115208, 0.32194129420260836], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [29.0363307803918, 16.365083417005035, 12.48644262896576, 9.45835402332432, 9.00451043972335, 7.537777548029591, 5.916363327525104, 3.827726870063189, 3.819926652649657, 2.547484312322191]}, \"tinfo\": {\"Term\": [\"dre\", \"color\", \"weater\", \"ize\", \"top\", \"e\", \"love\", \"great\", \"mall\", \"fit\", \"blue\", \"hirt\", \"pant\", \"t\", \"it\", \"i\", \"jean\", \"wa\", \"ordered\", \"ed\", \"thi\", \"de\", \"tore\", \"purcha\", \"perfect\", \"wear\", \"ual\", \"h\", \"on\", \"m\", \"mall\", \"large\", \"x\", \"che\", \"izing\", \"c\", \"maller\", \"reference\", \"larger\", \"xx\", \"l\", \"dd\", \"xl\", \"pound\", \"ran\", \"eemed\", \"broad\", \"awkward\", \"home\", \"ite\", \"tailored\", \"exchange\", \"ider\", \"gone\", \"build\", \"hung\", \"relaxed\", \"generally\", \"lb\", \"hapele\", \"petite\", \"ually\", \"medium\", \"normally\", \"bu\", \"nug\", \"big\", \"run\", \"ize\", \"p\", \"b\", \"regular\", \"u\", \"m\", \"ordered\", \"normal\", \"tight\", \"i\", \"area\", \"fit\", \"t\", \"me\", \"would\", \"wai\", \"houlder\", \"arm\", \"bit\", \"little\", \"top\", \"e\", \"length\", \"like\", \"wear\", \"love\", \"look\", \"de\", \"ign\", \"heer\", \"cami\", \"lace\", \"through\", \"thread\", \"purple\", \"ole\", \"nude\", \"beading\", \"coverage\", \"cratchy\", \"nag\", \"howing\", \"portion\", \"tring\", \"igner\", \"poor\", \"draw\", \"flim\", \"unu\", \"polye\", \"metallic\", \"billowy\", \"match\", \"falling\", \"toward\", \"ary\", \"wim\", \"neck\", \"front\", \"floral\", \"v\", \"embroidery\", \"blou\", \"underneath\", \"bra\", \"neckline\", \"thin\", \"fabric\", \"top\", \"al\", \"back\", \"look\", \"o\", \"like\", \"ee\", \"material\", \"detail\", \"hirt\", \"cut\", \"really\", \"ide\", \"pretty\", \"bottom\", \"leeve\", \"nice\", \"e\", \"make\", \"thi\", \"it\", \"would\", \"little\", \"beautiful\", \"much\", \"love\", \"color\", \"di\", \"aw\", \"wait\", \"appointed\", \"ju\", \"local\", \"arrived\", \"previou\", \"immediately\", \"andal\", \"knew\", \"tice\", \"finally\", \"reading\", \"oon\", \"covered\", \"picked\", \"tag\", \"flatter\", \"mail\", \"web\", \"idea\", \"een\", \"pay\", \"caught\", \"noted\", \"quickly\", \"giving\", \"chance\", \"bell\", \"tore\", \"price\", \"online\", \"can\", \"ale\", \"try\", \"excited\", \"on\", \"today\", \"tried\", \"loved\", \"worth\", \"review\", \"per\", \"t\", \"fir\", \"thought\", \"it\", \"i\", \"retailer\", \"one\", \"looked\", \"much\", \"picture\", \"would\", \"even\", \"like\", \"get\", \"back\", \"look\", \"kirt\", \"ed\", \"pant\", \"pair\", \"leg\", \"them\", \"cardigan\", \"they\", \"ankle\", \"thigh\", \"pilcro\", \"ri\", \"hu\", \"tated\", \"butt\", \"ag\", \"natural\", \"wingy\", \"worry\", \"thrilled\", \"receive\", \"do\", \"cular\", \"calve\", \"trou\", \"nt\", \"perfection\", \"crop\", \"bulk\", \"hopping\", \"hemmed\", \"luck\", \"legging\", \"athletic\", \"jean\", \"denim\", \"tretch\", \"the\", \"tunic\", \"re\", \"e\", \"wai\", \"long\", \"alway\", \"hort\", \"uper\", \"length\", \"comfortable\", \"love\", \"great\", \"fit\", \"i\", \"t\", \"wear\", \"perfect\", \"high\", \"like\", \"m\", \"look\", \"oft\", \"o\", \"tee\", \"pring\", \"wardrobe\", \"very\", \"highly\", \"addition\", \"pencil\", \"hoe\", \"poncho\", \"date\", \"muted\", \"machine\", \"honey\", \"both\", \"cu\", \"hrink\", \"wrinkled\", \"fuller\", \"overly\", \"hate\", \"her\", \"turtleneck\", \"tomer\", \"flop\", \"nervou\", \"flip\", \"travel\", \"fre\", \"drew\", \"ine\", \"ic\", \"ca\", \"ummer\", \"weat\", \"ual\", \"hirt\", \"red\", \"great\", \"recommend\", \"night\", \"comfy\", \"tyli\", \"kirt\", \"lightweight\", \"white\", \"love\", \"oft\", \"comfortable\", \"true\", \"perfect\", \"color\", \"bought\", \"purcha\", \"top\", \"black\", \"nice\", \"h\", \"ed\", \"cute\", \"fit\", \"thi\", \"well\", \"look\", \"ize\", \"i\", \"wear\", \"jean\", \"flattering\", \"dre\", \"ily\", \"jump\", \"wedding\", \"ting\", \"hourgla\", \"motif\", \"ilk\", \"maxi\", \"party\", \"hemline\", \"ilver\", \"pear\", \"cooler\", \"glove\", \"hug\", \"tomach\", \"plenty\", \"turquoi\", \"velvet\", \"hopefully\", \"onally\", \"igned\", \"flair\", \"walked\", \"turn\", \"tandard\", \"liner\", \"hower\", \"du\", \"ea\", \"y\", \"belt\", \"wrap\", \"appropriate\", \"holiday\", \"beautifully\", \"intere\", \"figure\", \"flattering\", \"knee\", \"uit\", \"perfect\", \"kirt\", \"thi\", \"down\", \"comfortable\", \"perfectly\", \"beautiful\", \"ummer\", \"fit\", \"wear\", \"love\", \"ed\", \"make\", \"on\", \"work\", \"well\", \"great\", \"fabric\", \"i\", \"length\", \"e\", \"weater\", \"jacket\", \"compliment\", \"ab\", \"olutely\", \"coat\", \"atile\", \"cozy\", \"outfit\", \"cold\", \"ton\", \"wool\", \"event\", \"blazer\", \"kimono\", \"everyone\", \"become\", \"remind\", \"tatement\", \"own\", \"faded\", \"pro\", \"darling\", \"write\", \"happened\", \"complement\", \"five\", \"attracted\", \"ticated\", \"ophi\", \"warm\", \"wore\", \"many\", \"ver\", \"winter\", \"paired\", \"received\", \"weather\", \"piece\", \"worn\", \"time\", \"itchy\", \"love\", \"it\", \"ve\", \"got\", \"wear\", \"day\", \"i\", \"oft\", \"leeve\", \"thi\", \"great\", \"get\", \"fall\", \"comfortable\", \"beautiful\", \"tic\", \"clo\", \"ela\", \"et\", \"cool\", \"ome\", \"tand\", \"te\", \"throw\", \"awe\", \"feeling\", \"fanta\", \"round\", \"ta\", \"combo\", \"rolled\", \"tretched\", \"trim\", \"evening\", \"allow\", \"appreciate\", \"panel\", \"ock\", \"ey\", \"dot\", \"no\", \"ro\", \"garment\", \"eriou\", \"jer\", \"pocket\", \"texture\", \"movement\", \"taple\", \"button\", \"in\", \"h\", \"ide\", \"year\", \"wi\", \"front\", \"up\", \"t\", \"out\", \"back\", \"tie\", \"zipper\", \"ye\", \"ub\", \"tantial\", \"dry\", \"adju\", \"hing\", \"occa\", \"econd\", \"tly\", \"beach\", \"what\", \"table\", \"meant\", \"ago\", \"clean\", \"daughter\", \"adore\", \"originally\", \"terday\", \"hone\", \"package\", \"bring\", \"beige\", \"awful\", \"trip\", \"cho\", \"head\", \"double\", \"obviou\", \"tantly\", \"wa\", \"hed\", \"ion\", \"hand\", \"purcha\", \"year\", \"ed\", \"mo\", \"e\", \"h\", \"one\", \"new\", \"plea\", \"time\", \"ver\", \"retailer\", \"t\", \"wore\", \"bought\", \"in\", \"black\", \"fir\", \"blue\", \"green\", \"grey\", \"gray\", \"pink\", \"kin\", \"orange\", \"vibrant\", \"tran\", \"yellow\", \"bright\", \"ive\", \"brown\", \"ilhouette\", \"hanger\", \"money\", \"tock\", \"hade\", \"combination\", \"walk\", \"expen\", \"ition\", \"crotch\", \"lighter\", \"lavender\", \"keeper\", \"wri\", \"vibe\", \"mix\", \"peach\", \"navy\", \"dark\", \"color\", \"tone\", \"light\", \"pictured\", \"ordered\", \"photo\", \"fall\"], \"Freq\": [13085.0, 7064.0, 2964.0, 9637.0, 8587.0, 8640.0, 9255.0, 6146.0, 4826.0, 9884.0, 1468.0, 3337.0, 2136.0, 12312.0, 6252.0, 18703.0, 2573.0, 1548.0, 3613.0, 3820.0, 4885.0, 2255.0, 2205.0, 2426.0, 3817.0, 6539.0, 2150.0, 2345.0, 3744.0, 6336.0, 4825.26111625976, 2835.637464470669, 2394.206019680212, 1197.5004176206078, 715.3789234309489, 691.3548340600402, 650.3054880080018, 583.1913280480405, 549.2465356759224, 522.1576205864266, 450.95185202314076, 359.3092104268676, 357.28524653463205, 301.2695729772682, 294.78544679583274, 273.87099852908796, 255.4447840149428, 210.48484432318747, 201.1497324649312, 201.1056390763601, 191.19354846800616, 177.25691762104898, 176.0275114337432, 174.35980149267624, 169.15565996736663, 165.65507037734258, 156.00748852920057, 147.59779633318303, 2140.7838329203155, 145.37458705294227, 2643.7191083656185, 1898.1715916167523, 2170.71927277656, 839.747188098153, 1448.0318315115403, 491.31225821796124, 1675.9764973565527, 2483.8433919495797, 8318.156384192547, 802.6809963849186, 532.775050698274, 1100.2108053711736, 3096.1729720169856, 4984.778309591183, 2926.234680188089, 478.4141942783013, 1368.688589409047, 9203.54255016645, 662.6995980375837, 5241.678459070653, 5493.062138855767, 1866.851774073019, 2848.349150040392, 1852.9729287721366, 1089.9479273604097, 1008.9972104956225, 1626.5825161958446, 1861.6826880809037, 2790.3426728818467, 2770.2827080715165, 1529.3000207740395, 2377.140073310682, 1992.1040209314478, 1325.6360110930837, 1244.7467671162224, 2254.738513173668, 1559.2837210574303, 903.0205813291302, 744.9710608647406, 689.6201604885786, 426.71091177119087, 222.1393903554803, 213.8486025619132, 198.4558224871945, 192.74544760319267, 187.73200045510626, 158.3247891172094, 158.19502438456445, 152.15310925576148, 148.85585846539072, 141.35519823195816, 134.91430995887228, 132.345901268051, 121.17732729138513, 117.99224909468892, 112.85691407419874, 111.24545670496694, 107.7011239231007, 105.41681265372749, 104.5196571650944, 94.62430788824469, 92.58411388806218, 87.97782920297806, 86.96117651262327, 85.27874746998216, 691.1586188375309, 1157.375966747257, 208.41050254252144, 225.30830064254857, 486.3177291477051, 782.662214975589, 612.4166989263952, 603.1796705972123, 472.19135055161576, 844.8107585421812, 2534.5973699666542, 3816.786053000892, 1452.1134277564138, 1624.2116045870591, 2784.161880403842, 1689.7555690379875, 2903.8455108398966, 1005.713330104558, 1430.4582821968063, 719.0018374289776, 1456.1841658763358, 944.1897616261798, 1424.4003662873288, 900.079751198197, 1003.4363071108509, 789.163444067349, 1000.289399713829, 1187.3122211540838, 1944.682622674652, 946.1113086023604, 1386.9987085897728, 1341.5330062231571, 1164.0082249385273, 1027.5711231534704, 962.446230920097, 950.8614331845611, 1122.4331683447695, 1063.392758257997, 1353.6872421568378, 1134.3987728399482, 577.4808135001808, 531.553501360616, 441.2734940742536, 361.5470044554654, 333.6694398367775, 281.6974542229922, 270.67338328434766, 246.53325532857178, 233.24273122766672, 218.58450228495525, 198.76520124323554, 191.6237381293669, 190.64668254149126, 189.5478747876162, 183.4968143145236, 182.58668915232852, 178.77861849147325, 174.27194765190245, 169.97450646809153, 157.0100408773152, 149.38373136469198, 135.55876182691617, 131.8485697060679, 129.18016806791357, 128.64976994803644, 128.3854856926238, 126.18917863255928, 125.35143945758136, 1965.435324751497, 1260.4687274935613, 1434.7804830030175, 770.2542336036054, 1207.3303162107586, 919.002469669063, 331.5929555368031, 2085.0764102070693, 307.71081354588546, 1276.4359585488626, 835.1724885145054, 461.41116926808405, 766.9465665627158, 799.8441348782402, 3470.5507699588625, 683.675980059373, 584.9857145915356, 1885.8380609744718, 3560.693678540269, 888.752223677707, 1183.0343499179194, 633.0799048067785, 914.837525446229, 600.7926053626516, 1096.7433339062961, 722.558654213804, 1168.178456666364, 674.1723918626388, 667.1792047017524, 765.2589795273983, 619.831317563051, 593.1186262178214, 2135.7669464121736, 1165.7583103600016, 674.7195538599923, 582.1418172732889, 519.755894187047, 500.57832185152466, 379.85387148100773, 330.2743984341121, 289.2451019354484, 265.27745383678786, 160.62593501952657, 157.8860322448815, 155.2781689295173, 149.61822863189784, 135.30103551206972, 115.13092457700266, 112.86426399159443, 108.4431847606234, 107.72844139242706, 107.33109669390664, 105.45203743725001, 99.70929529550898, 97.84370036793804, 94.19273372371168, 89.29310384687116, 85.63709752862644, 84.07194276765966, 81.36504985783483, 80.73498141260353, 79.93490796381977, 842.4725622784481, 219.6475229213359, 1848.020777921091, 444.5744403551654, 515.7156211243595, 1255.9387748096544, 304.2443813358339, 441.7405980568182, 2453.815129275586, 1038.3595173065376, 855.4168642011097, 366.5886431168574, 736.6889310897037, 575.2320210202042, 799.6095971871198, 806.3717645892934, 1501.921769471521, 1190.9699851911794, 1351.4392535443887, 1855.7558039957676, 1424.134065019961, 963.075186929028, 760.0269895121647, 458.313230087907, 839.2374275369327, 700.7250781425412, 674.6212466188075, 569.7404562315379, 486.2732071504272, 656.55241576592, 536.9863232105919, 404.90240687572594, 365.3008278189643, 329.66636995264645, 197.80713709894826, 164.84313252599128, 120.21397070778353, 115.99329895072051, 115.31086825637155, 111.63928684742389, 109.87272517128694, 107.73331430031733, 104.99598692506432, 92.42238010172888, 87.35383966391647, 87.12782078018076, 83.97060925258106, 80.46318640242379, 79.18633364045132, 76.43131018206697, 75.4979437512768, 73.43804930627103, 72.52127545229854, 68.88959619193892, 68.06447733338051, 67.77491087953874, 62.40567296767722, 60.667282688228795, 59.51720520956593, 414.84918888720284, 1151.9352075526342, 1116.4409429666862, 150.68981643254233, 1317.7105150424536, 1835.233353821206, 604.6368257478996, 2914.581643288724, 590.383234515514, 243.24476122751625, 502.96560738881453, 219.0066128834674, 1162.6853421604535, 383.99905461155004, 732.9879160734099, 2638.42435845671, 1210.0677922133495, 1147.0154245637561, 744.2197551764085, 1252.8352189340787, 1808.9815463474092, 1036.0594959956986, 871.2138206073324, 1979.2752803848377, 708.7642572470447, 945.0245112014494, 809.857973968649, 1043.1115730394652, 892.8910346614396, 1659.286340946065, 1034.5002575673457, 847.3328564663158, 1061.398239955592, 1134.980616692698, 1330.2098830787168, 900.649483688708, 724.6606335307188, 705.6787896226779, 13084.946439545281, 503.888413712224, 411.24219174544925, 319.12318101052165, 272.0227079098867, 245.78268999278103, 216.41930030345705, 174.64151859782856, 173.36177960208767, 169.51742170290393, 144.3004988172295, 140.45081257700272, 125.68252549649543, 123.56793720652497, 115.67232647730506, 113.40272094879833, 112.83628348766436, 100.39978153358952, 99.21043021260274, 91.32005410988492, 85.80842081251537, 84.9114588593179, 82.78094579128036, 79.60868849816084, 77.64617213258228, 77.53054177683153, 76.20666992619516, 74.09838728605203, 73.60811297113388, 72.77787577109859, 1441.9487985201142, 1187.796677079029, 450.76940536217705, 212.82821264510838, 180.98766649463857, 121.0952121043873, 305.3788190045227, 199.13350595802567, 362.8475208341827, 1139.1197379703967, 376.7619345686459, 401.3546382847899, 1019.201219030071, 747.7717241644491, 1045.9982226274653, 425.9145151360154, 738.1319251744999, 486.6956511303809, 699.5511480946997, 463.4384331740563, 1119.9247508331919, 847.2404450397239, 986.4411859670948, 612.2027697817858, 484.7117410738808, 584.9236985857028, 487.24069490059327, 479.3386848070051, 550.6610733485875, 472.95726007942017, 562.5991277409935, 377.5506896965157, 376.4752484000635, 2963.1282478703297, 1117.3128809454352, 1053.5522960558055, 928.1985503746183, 879.1981042581219, 555.0873319542424, 509.3224280985649, 312.1477395978138, 276.08689857024393, 228.1594253169429, 197.9249393722272, 190.8734344307335, 152.69868659813096, 146.56184084676542, 132.10001395898388, 130.72478870682602, 117.138121400978, 106.52803696665715, 90.69842449753496, 90.11959078713323, 86.34687907409065, 83.67478679757681, 77.40342801495316, 77.25222826440455, 75.16529552008897, 72.47476168667663, 72.26036676622049, 68.8085906832603, 68.19321536937449, 67.526934002842, 601.5591726657061, 760.8067976288148, 816.8750991497873, 627.9630687803439, 385.82330408482005, 257.36786716946534, 454.10956262545267, 240.7585708938968, 551.1783944043722, 532.5232727181559, 502.66375458903383, 170.18160828622723, 1629.988667108777, 1275.3992447484472, 452.65441345205824, 637.3304970119837, 1071.2228172398045, 415.0214480879063, 1248.8635781930645, 575.9679239837202, 451.73004486103315, 584.4983682324079, 626.5914792995176, 415.88012060273223, 360.0448867353262, 404.89012958829227, 390.4390944263995, 679.2193205050825, 662.8318100555435, 481.47334778940836, 356.2631512134884, 299.61264709517775, 261.5794734830935, 232.93031856417082, 232.01827272303757, 230.3644401126377, 210.67996512027065, 179.54885117095847, 168.97176806955466, 160.8389672785161, 153.4543845409634, 139.01305139949287, 130.99046623188116, 125.26942421663635, 124.65206172197857, 121.3568103753694, 119.99835454800987, 119.96410422042386, 117.70204616186791, 116.14582494556889, 113.77391837706162, 112.9181292768522, 110.43591190735035, 109.56721944831635, 108.62601527947042, 108.21930113738362, 104.11079146654325, 380.5508348817478, 206.26291017005525, 130.0510092512428, 200.5325407531733, 374.7481577069847, 400.2539782741846, 487.39714521750057, 332.82265667235464, 190.8052709604052, 210.0278764101882, 212.80731972690333, 196.15135414919527, 310.7951411080921, 184.27961138439917, 231.07772799876804, 158.6982062316294, 152.03141191948092, 374.5406582712934, 321.8891519465454, 284.3001198329797, 282.17232407275463, 264.83320121069045, 260.62184491572265, 252.78553401426674, 240.3911223540469, 197.9565283615201, 178.01456955244845, 176.10690509989197, 175.00391467848664, 170.6821195797763, 155.26545147572122, 151.1997186285682, 150.56163228552953, 145.53767761226896, 142.80248878509138, 133.31078990720397, 128.37525140855777, 120.64211984899376, 115.35808647425479, 112.26702118734566, 112.03795463551137, 103.24188860105238, 101.47790043224425, 100.51038378115041, 97.8385354547555, 95.2486512018348, 90.13067632079297, 1321.6847084238207, 548.7346069744762, 589.4254782304826, 228.42953744917529, 732.2462038692697, 340.95537541285523, 700.9372168654365, 164.48114154332157, 954.0755471565561, 488.93444396820877, 515.7245991527093, 217.43846796375075, 208.83156857912275, 294.2731549542826, 251.80150378359866, 297.6865674855347, 432.58715239985065, 234.5167658245201, 281.7229430305695, 245.7089020495756, 219.44511891013957, 206.17119970081313, 1467.8230777003025, 718.5438608781825, 635.1332641572199, 477.6100222780144, 435.2628867634803, 430.54166267626147, 364.8799699038362, 331.22279256849936, 287.41675526656974, 259.38061195599954, 250.29868137993574, 241.35950998138065, 237.01138179227814, 179.79868679218518, 169.4281048829379, 169.40008875631727, 162.07112070752743, 155.62252505107185, 152.79347540712553, 137.87854383279338, 131.55577641944495, 129.2256418675856, 121.31082367230171, 120.57394343753306, 120.52334971533153, 113.92676448046717, 106.13620902767498, 101.68096620975844, 98.57428000869092, 98.22070309801667, 391.0736004322754, 306.06423847009023, 2346.0746420100863, 136.68661871971577, 216.56822413717842, 156.62983873030342, 216.54018991228477, 157.75489977374286, 139.31400835663996], \"Total\": [13085.0, 7064.0, 2964.0, 9637.0, 8587.0, 8640.0, 9255.0, 6146.0, 4826.0, 9884.0, 1468.0, 3337.0, 2136.0, 12312.0, 6252.0, 18703.0, 2573.0, 1548.0, 3613.0, 3820.0, 4885.0, 2255.0, 2205.0, 2426.0, 3817.0, 6539.0, 2150.0, 2345.0, 3744.0, 6336.0, 4826.189269783535, 2836.565635490636, 2395.1341609898327, 1198.4285412300073, 716.3070821927764, 692.282994263566, 651.23363975316, 584.1194477438439, 550.174685332453, 523.0857379194899, 451.8800003600759, 360.237363384163, 358.2133549809781, 302.19772761627553, 295.7135997763227, 274.79921872965144, 256.37294539901654, 211.41336485976484, 202.07815275216726, 202.03414936414825, 192.12184410524245, 178.18499598883562, 176.95592502494978, 175.28815129603126, 170.0838284811467, 166.58347888079996, 156.9358987475037, 148.52600920889012, 2154.2641779912897, 146.3028242244557, 2674.195491295573, 1934.6695990563687, 2219.1298194707206, 867.3245615842189, 1522.4255138944052, 505.0412969779682, 1810.9380647180667, 2729.6948010915835, 9637.570440514244, 849.7795999860784, 556.9411081455032, 1207.3788005391627, 3648.15467197901, 6336.632282841408, 3613.5585146944336, 513.7655598751214, 1762.2815243451132, 18703.608821743732, 756.3840163665698, 9884.048112918668, 12312.311618402648, 3000.642909854632, 5323.932079637117, 3167.496561746217, 1508.9217483507755, 1351.9316958084862, 2939.609543308773, 3992.530175449426, 8587.134651993178, 8640.870480172944, 2985.2635246255127, 7519.638018308115, 6539.315457104674, 9255.834550454258, 6871.831191502692, 2255.686738632325, 1560.2092104102917, 903.946114611112, 745.8965639839992, 690.5456636681295, 427.6364048207955, 223.06491993566027, 214.77425878238057, 199.38134566008824, 193.67090491004836, 188.6576540820419, 159.2502653774909, 159.1205498200945, 153.07864395289005, 149.7813847122568, 142.28067887650184, 135.8398647186342, 133.27146371290866, 122.10285681266498, 118.9178523178827, 113.78250955225666, 112.17103346424585, 108.62659503906953, 106.34233479158713, 105.44521861621851, 95.54990226151233, 93.50977652858397, 88.90357750338218, 87.88683333823803, 86.20418294691059, 744.8411922189671, 1479.3415379761373, 227.32168170060496, 248.27650194747383, 579.0574179744814, 1009.4116880646114, 770.372230803867, 759.1325368566924, 584.1172639203388, 1148.5856132817921, 5104.783419919905, 8587.134651993178, 2614.900310751528, 3264.653374463015, 6871.831191502692, 3606.419544419658, 7519.638018308115, 1842.7410836257868, 2997.908913156169, 1208.202284855247, 3337.3582607178037, 1865.124694739219, 3572.6645280675007, 1824.8389812784549, 2167.8212176043135, 1547.8279296649796, 2271.003348472684, 3013.8376231428756, 8640.870480172944, 2175.991110898161, 4885.954371646043, 6252.1558718525275, 5323.932079637117, 3992.530175449426, 3029.3769929577447, 2867.2954434433195, 9255.834550454258, 7064.425115268752, 1354.6123314893632, 1135.323826707457, 578.4058859243343, 532.4785463971859, 442.1985501023373, 362.47206267658584, 334.5944921994695, 282.6225502995088, 271.5984579442074, 247.45868424859628, 234.16782855223005, 219.50953741302092, 199.6903116962887, 192.54883354599437, 191.57175498429538, 190.47315811819732, 184.42193722192167, 183.51178445115377, 179.70384661415474, 175.19700514694708, 170.89961382895152, 157.93517438132366, 150.30880882008645, 136.48393866820825, 132.77365553919896, 130.10530675530828, 129.57515139293847, 129.3106968721773, 127.11430430026756, 126.27681425666762, 2205.101242876909, 1479.2374218219227, 1704.919541094185, 938.5322058771327, 1592.4460339238485, 1262.4800099764311, 395.138749053367, 3744.9818163917057, 363.15213261232446, 2177.5185206885676, 1275.7802456184072, 659.0352213031957, 1386.4564544355571, 1492.0855311297537, 12312.311618402648, 1238.9789300626746, 1034.2687720829379, 6252.1558718525275, 18703.608821743732, 2188.083072235122, 3653.170378666302, 1396.6587527517609, 2867.2954434433195, 1321.4372269132193, 5323.932079637117, 2160.2934471495287, 7519.638018308115, 2076.703980431283, 3264.653374463015, 6871.831191502692, 2531.0175285076766, 3820.093443355543, 2136.6874874391, 1166.7384824622516, 675.6400873040027, 583.0623436472288, 520.6766365233907, 501.49885106440536, 380.77441723132966, 331.1949848669626, 290.16560155217456, 266.19800334976037, 161.54662539882798, 158.80676614597851, 156.1987050448903, 150.53873348384582, 136.22166927559658, 116.0516014522337, 113.78502271052527, 109.3638461211773, 108.649164524785, 108.25180668370062, 106.372587053995, 100.63005711553879, 98.76424022300654, 95.11383023935767, 90.21391195564559, 86.55767144327592, 84.99262223308571, 82.2857905447816, 81.65550332920705, 80.85616106405293, 972.6610798359077, 236.19571464766042, 2573.504700248368, 580.250487287847, 748.1204868984922, 2455.145852377871, 432.1443622469544, 735.2604291096183, 8640.870480172944, 3167.496561746217, 2491.322117476844, 691.4511547455629, 2398.1257465290305, 1682.2273540399694, 2985.2635246255127, 3100.773536032363, 9255.834550454258, 6146.983476747949, 9884.048112918668, 18703.608821743732, 12312.311618402648, 6539.315457104674, 3817.663272685351, 1236.161742007655, 7519.638018308115, 6336.632282841408, 6871.831191502692, 3335.956501507977, 3606.419544419658, 657.480830571841, 537.9147863351262, 405.8309262344939, 366.2293120895849, 330.59478105007054, 198.7356355649244, 165.77164489413863, 121.14256840022612, 116.92177263531035, 116.23938389161604, 112.56789004175263, 110.80134799247864, 108.66241845084377, 105.92462294373526, 93.35103631332423, 88.282319526128, 88.05639229726003, 84.89924980917662, 81.39171774092283, 80.11495168807525, 77.36006993422812, 76.42650636529775, 74.36664526646263, 73.44973376674234, 69.81845077886096, 68.99290820013603, 68.70335792219568, 63.33414764629959, 61.59693222642386, 60.44597853314519, 472.6816689996215, 1476.9933106821875, 1580.7091389903458, 172.26061071292972, 2150.4829958091277, 3337.3582607178037, 916.0734955429566, 6146.983476747949, 1017.0618878860524, 331.18389206160714, 832.11844958051, 292.63785541237655, 2531.0175285076766, 607.5743861767683, 1537.769610362046, 9255.834550454258, 3335.956501507977, 3100.773536032363, 1671.9776464312774, 3817.663272685351, 7064.425115268752, 3125.528031718166, 2426.8712196462766, 8587.134651993178, 1827.4172755157729, 3013.8376231428756, 2345.085819794802, 3820.093443355543, 2918.275200365614, 9884.048112918668, 4885.954371646043, 3415.5095987810505, 6871.831191502692, 9637.570440514244, 18703.608821743732, 6539.315457104674, 2573.504700248368, 3614.1307375408687, 13085.87345104241, 504.815893903285, 412.16926199677795, 320.0501337897191, 272.9497799522976, 246.7097303547369, 217.34657260145087, 175.56857109495897, 174.28875631445183, 170.4444630160183, 145.22767127181194, 141.37838076558998, 126.60955343482898, 124.49527526978781, 116.59937963386082, 114.32980275449768, 113.76335247509498, 101.32686625864513, 100.13764183949974, 92.24710823260155, 86.73562590378238, 85.83866541454994, 83.70797534490619, 80.53586895981111, 78.5733483389086, 78.45769384514338, 77.13385946657132, 75.02558639192983, 74.53512950002268, 73.70514266179423, 1552.9298453550575, 1387.6549417882281, 519.6514633983954, 251.1185239589727, 216.24867697256505, 138.97274348297142, 464.15088755535527, 278.732525024429, 643.7391068241915, 3614.1307375408687, 735.0267904946212, 823.3023570189116, 3817.663272685351, 2531.0175285076766, 4885.954371646043, 1083.0028362337346, 3100.773536032363, 1529.9861911677872, 3029.3769929577447, 1580.7091389903458, 9884.048112918668, 6539.315457104674, 9255.834550454258, 3820.093443355543, 2175.991110898161, 3744.9818163917057, 2592.714779859889, 3415.5095987810505, 6146.983476747949, 5104.783419919905, 18703.608821743732, 2985.2635246255127, 8640.870480172944, 2964.047422925355, 1118.231746505022, 1054.4711357477015, 929.1174238189068, 880.116971229576, 556.0061934520185, 510.2412942850812, 313.06660887067255, 277.0058417548184, 229.07838989132586, 198.84383092900765, 191.7922844782866, 153.61762972865333, 147.48071197206315, 133.0189195355356, 131.64374774146384, 118.05709083535218, 107.44714237397326, 91.6173414279735, 91.03857372830173, 87.2659599051949, 84.59391983667611, 78.32248484898942, 78.1714342792107, 76.08430832619035, 73.3936451304203, 73.17948524384295, 69.72770869167623, 69.11210219404244, 68.44583569606453, 691.0990361093623, 996.1354431998758, 1144.0461312991922, 911.476478648178, 514.5428484399813, 320.891210781973, 839.6653380176912, 364.9916937103291, 1246.557053730632, 1216.8425040066056, 1364.604974860306, 247.20818351155037, 9255.834550454258, 6252.1558718525275, 1188.890979794899, 2347.837362283974, 6539.315457104674, 1251.6265521385208, 18703.608821743732, 3335.956501507977, 2271.003348472684, 4885.954371646043, 6146.983476747949, 2076.703980431283, 1409.8940624123122, 3100.773536032363, 3029.3769929577447, 680.1399250964319, 663.7524155675796, 482.39395029463344, 357.1837421782467, 300.533287811834, 262.50003539346807, 233.85097774989995, 232.9390024444789, 231.28511469922051, 211.6005191408909, 180.46957652327137, 169.89235258889838, 161.75961828898943, 154.37500797595865, 139.93378658984162, 131.91118595893363, 126.19023632999685, 125.57274473074855, 122.27744339068983, 120.91897224058407, 120.88486079615186, 118.6226664701647, 117.0664807258506, 114.69450318691592, 113.83873028207, 111.35656290263182, 110.48792581203452, 109.54665520333346, 109.13994675181195, 105.03137745778685, 615.2273042335236, 283.9017601484912, 146.17830106732814, 309.4067468811181, 954.4225928004023, 1444.6659226219274, 2345.085819794802, 1824.8389812784549, 720.4873073871698, 1111.6244219919924, 1479.3415379761373, 1026.8729593765918, 12312.311618402648, 926.5962661792983, 3264.653374463015, 448.061668123019, 388.36031514526894, 375.4593609996848, 322.80781870209864, 285.21878354410586, 283.09090557185016, 265.75189069005876, 261.5404607816116, 253.70419698588663, 241.309812528858, 198.87517804913705, 178.93327135733256, 177.0256393834987, 175.92256859281264, 171.60089153045286, 156.1841439090121, 152.11840211446074, 151.48030306491688, 146.45642297409887, 143.72117210806704, 134.22941949540825, 129.29391331529362, 121.56086285363179, 116.27682861381706, 113.18571386380151, 112.9567406767637, 104.16054729924508, 102.39664906298164, 101.42904319960661, 98.75752109513735, 96.1674098936494, 91.04934355369139, 1548.7535159886415, 636.3016326681071, 688.9356442988466, 250.92929572098203, 2426.8712196462766, 720.4873073871698, 3820.093443355543, 241.75981644151256, 8640.870480172944, 2345.085819794802, 3653.170378666302, 505.7327301170231, 487.7609080693842, 1364.604974860306, 911.476478648178, 2188.083072235122, 12312.311618402648, 996.1354431998758, 3125.528031718166, 1444.6659226219274, 1827.4172755157729, 1238.9789300626746, 1468.7417112987089, 719.4624807023218, 636.0519186427896, 478.52868744042433, 436.18149046317455, 431.4603417481, 365.7985767596656, 332.14144130982237, 288.33538268041207, 260.29920575046015, 251.21729945650003, 242.2781613468334, 237.93003737092752, 180.7174222576095, 170.34688966406466, 170.31882599321557, 162.98981861387244, 156.54110541004596, 153.71217728846915, 138.79752431770416, 132.47439167843413, 130.144206530901, 122.22962356496232, 121.49258534047489, 121.44196908725824, 114.8454308421169, 107.05491553112299, 102.59968724649052, 99.49297318101499, 99.13934513917879, 565.1584121169193, 431.43665931317946, 7064.425115268752, 216.1704383986891, 1370.6495060483187, 468.70271875369986, 3613.5585146944336, 1016.6111103171262, 1409.8940624123122], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.8265, -4.3581, -4.5274, -5.2202, -5.7354, -5.7695, -5.8307, -5.9396, -5.9996, -6.0502, -6.1968, -6.424, -6.4296, -6.6002, -6.6219, -6.6955, -6.7652, -6.9587, -7.0041, -7.0043, -7.0549, -7.1306, -7.1375, -7.147, -7.1773, -7.1983, -7.2583, -7.3137, -4.6392, -7.3288, -4.4282, -4.7595, -4.6253, -5.5751, -5.0302, -6.1111, -4.884, -4.4906, -3.282, -5.6202, -6.0301, -5.3049, -4.2702, -3.794, -4.3267, -6.1377, -5.0866, -3.1808, -5.8118, -3.7438, -3.6969, -4.7762, -4.3537, -4.7836, -5.3143, -5.3915, -4.9139, -4.7789, -4.3742, -4.3815, -4.9756, -4.5345, -4.7112, -5.1185, -5.1815, -4.014, -4.3828, -4.929, -5.1214, -5.1986, -5.6787, -6.3315, -6.3695, -6.4442, -6.4734, -6.4997, -6.6701, -6.6709, -6.7099, -6.7318, -6.7835, -6.8301, -6.8493, -6.9375, -6.9641, -7.0086, -7.023, -7.0554, -7.0768, -7.0854, -7.1849, -7.2066, -7.2577, -7.2693, -7.2888, -5.1964, -4.6809, -6.3953, -6.3173, -5.5479, -5.0721, -5.3174, -5.3325, -5.5774, -4.9957, -3.897, -3.4876, -4.454, -4.342, -3.8031, -4.3024, -3.761, -4.8213, -4.469, -5.1569, -4.4512, -4.8844, -4.4733, -4.9323, -4.8236, -5.0638, -4.8267, -4.6553, -4.1619, -4.8824, -4.4999, -4.5332, -4.6751, -4.7998, -4.8653, -4.8774, -4.7115, -4.7655, -4.2537, -4.4304, -5.1056, -5.1885, -5.3746, -5.5739, -5.6541, -5.8234, -5.8633, -5.9568, -6.0122, -6.0771, -6.1721, -6.2087, -6.2138, -6.2196, -6.2521, -6.257, -6.2781, -6.3036, -6.3286, -6.4079, -6.4577, -6.5549, -6.5826, -6.6031, -6.6072, -6.6092, -6.6265, -6.6331, -3.8808, -4.325, -4.1955, -4.8175, -4.3681, -4.641, -5.6604, -3.8217, -5.7351, -4.3124, -4.7366, -5.33, -4.8218, -4.7798, -3.3122, -4.9368, -5.0927, -3.9221, -3.2865, -4.6744, -4.3884, -5.0137, -4.6455, -5.066, -4.4642, -4.8815, -4.4011, -4.9508, -4.9612, -4.824, -5.0348, -5.0789, -3.5199, -4.1254, -4.6722, -4.8198, -4.9332, -4.9707, -5.2467, -5.3866, -5.5192, -5.6057, -6.1074, -6.1246, -6.1413, -6.1784, -6.279, -6.4404, -6.4603, -6.5003, -6.5069, -6.5106, -6.5283, -6.5843, -6.6031, -6.6412, -6.6946, -6.7364, -6.7548, -6.7876, -6.7953, -6.8053, -4.4502, -5.7945, -3.6646, -5.0894, -4.941, -4.0509, -5.4687, -5.0958, -3.3811, -4.2411, -4.4349, -5.2823, -4.5843, -4.8317, -4.5024, -4.494, -3.872, -4.104, -3.9776, -3.6605, -3.9252, -4.3164, -4.5532, -5.059, -4.454, -4.6344, -4.6724, -4.8413, -4.9997, -4.6503, -4.8514, -5.1337, -5.2366, -5.3393, -5.85, -6.0323, -6.3481, -6.3838, -6.3897, -6.4221, -6.438, -6.4577, -6.4834, -6.611, -6.6674, -6.67, -6.7069, -6.7495, -6.7655, -6.8009, -6.8132, -6.8409, -6.8535, -6.9048, -6.9169, -6.9211, -7.0037, -7.0319, -7.0511, -5.1094, -4.0881, -4.1194, -6.1221, -3.9537, -3.6224, -4.7327, -3.1599, -4.7566, -5.6433, -4.9168, -5.7482, -4.0789, -5.1867, -4.5402, -3.2594, -4.0389, -4.0924, -4.525, -4.0042, -3.6368, -4.1942, -4.3675, -3.5469, -4.5738, -4.2861, -4.4405, -4.1874, -4.3429, -3.7232, -4.1957, -4.3952, -4.17, -4.103, -3.9442, -4.3342, -4.5516, -4.5782, -1.4803, -4.7372, -4.9404, -5.194, -5.3537, -5.4551, -5.5823, -5.7968, -5.8042, -5.8266, -5.9876, -6.0147, -6.1258, -6.1428, -6.2088, -6.2286, -6.2336, -6.3504, -6.3623, -6.4452, -6.5074, -6.5179, -6.5433, -6.5824, -6.6074, -6.6089, -6.6261, -6.6541, -6.6608, -6.6721, -3.6858, -3.8797, -4.8486, -5.5991, -5.7611, -6.163, -5.238, -5.6656, -5.0656, -3.9215, -5.0279, -4.9647, -4.0328, -4.3424, -4.0068, -4.9053, -4.3554, -4.7719, -4.4091, -4.8209, -3.9385, -4.2176, -4.0654, -4.5425, -4.776, -4.5881, -4.7708, -4.7871, -4.6484, -4.8005, -4.627, -5.0258, -5.0287, -2.7233, -3.6987, -3.7574, -3.8841, -3.9383, -4.3982, -4.4843, -4.9739, -5.0966, -5.2873, -5.4294, -5.4657, -5.6889, -5.7299, -5.8338, -5.8442, -5.954, -6.0489, -6.2098, -6.2162, -6.259, -6.2904, -6.3683, -6.3703, -6.3976, -6.4341, -6.4371, -6.486, -6.495, -6.5048, -4.3178, -4.083, -4.0119, -4.2749, -4.762, -5.1668, -4.599, -5.2335, -4.4053, -4.4397, -4.4974, -5.5805, -3.321, -3.5663, -4.6022, -4.26, -3.7408, -4.689, -3.5873, -4.3613, -4.6043, -4.3466, -4.277, -4.6869, -4.8311, -4.7137, -4.7501, -3.7609, -3.7854, -4.105, -4.4062, -4.5794, -4.7151, -4.8311, -4.8351, -4.8422, -4.9315, -5.0914, -5.1522, -5.2015, -5.2485, -5.3473, -5.4068, -5.4514, -5.4564, -5.4832, -5.4944, -5.4947, -5.5137, -5.527, -5.5477, -5.5552, -5.5775, -5.5853, -5.594, -5.5977, -5.6364, -4.3403, -4.9527, -5.414, -4.9809, -4.3556, -4.2898, -4.0928, -4.4743, -5.0306, -4.9346, -4.9215, -5.003, -4.5428, -5.0654, -4.8391, -5.2149, -5.2578, -4.3541, -4.5056, -4.6298, -4.6373, -4.7007, -4.7168, -4.7473, -4.7976, -4.9918, -5.098, -5.1088, -5.115, -5.14, -5.2347, -5.2612, -5.2655, -5.2994, -5.3184, -5.3872, -5.4249, -5.487, -5.5318, -5.559, -5.561, -5.6428, -5.66, -5.6696, -5.6965, -5.7234, -5.7786, -3.0932, -3.9722, -3.9007, -4.8486, -3.6837, -4.4481, -3.7274, -5.1771, -3.4191, -4.0876, -4.0343, -4.8979, -4.9383, -4.5953, -4.7512, -4.5838, -4.2101, -4.8223, -4.6389, -4.7757, -4.8887, -4.9511, -2.5832, -3.2975, -3.4209, -3.7059, -3.7988, -3.8097, -3.9752, -4.0719, -4.2138, -4.3164, -4.3521, -4.3884, -4.4066, -4.6829, -4.7423, -4.7425, -4.7867, -4.8273, -4.8456, -4.9483, -4.9953, -5.0132, -5.0764, -5.0825, -5.0829, -5.1392, -5.21, -5.2529, -5.2839, -5.2875, -3.9058, -4.1509, -2.1142, -4.957, -4.4968, -4.8208, -4.4969, -4.8137, -4.938], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2364, 1.2363, 1.2362, 1.2358, 1.2353, 1.2353, 1.2352, 1.235, 1.2349, 1.2348, 1.2346, 1.234, 1.234, 1.2335, 1.2335, 1.2332, 1.233, 1.2322, 1.232, 1.232, 1.2318, 1.2314, 1.2314, 1.2313, 1.2312, 1.231, 1.2307, 1.2304, 1.2303, 1.2303, 1.2252, 1.2176, 1.2146, 1.2043, 1.1865, 1.2091, 1.1592, 1.1422, 1.0894, 1.1796, 1.1923, 1.1437, 1.0726, 0.9967, 1.0256, 1.1653, 0.9839, 0.5275, 1.1044, 0.6023, 0.4295, 0.762, 0.6111, 0.7005, 0.9114, 0.944, 0.6448, 0.4737, 0.1125, 0.0991, 0.5677, 0.085, 0.048, -0.7067, -0.4719, 1.8096, 1.8094, 1.809, 1.8088, 1.8087, 1.8079, 1.8059, 1.8057, 1.8054, 1.8052, 1.8051, 1.8042, 1.8042, 1.804, 1.8038, 1.8035, 1.8032, 1.8031, 1.8024, 1.8022, 1.8019, 1.8017, 1.8015, 1.8013, 1.8012, 1.8003, 1.8001, 1.7996, 1.7994, 1.7992, 1.7352, 1.5646, 1.7232, 1.7129, 1.6355, 1.5556, 1.5806, 1.5801, 1.5973, 1.5028, 1.1099, 0.9992, 1.2218, 1.1119, 0.9065, 1.0519, 0.8585, 1.2045, 1.0701, 1.291, 0.9807, 1.1293, 0.8905, 1.1033, 1.0397, 1.1364, 0.9901, 0.8785, 0.3186, 0.9771, 0.5508, 0.2709, 0.2897, 0.4528, 0.6634, 0.7063, -0.2997, -0.0836, 2.0798, 2.0797, 2.0789, 2.0788, 2.0784, 2.078, 2.0778, 2.0772, 2.0771, 2.0768, 2.0766, 2.0763, 2.0759, 2.0757, 2.0757, 2.0757, 2.0755, 2.0755, 2.0754, 2.0752, 2.0751, 2.0747, 2.0744, 2.0737, 2.0735, 2.0734, 2.0734, 2.0733, 2.0732, 2.0732, 1.9655, 1.9205, 1.908, 1.8829, 1.8037, 1.763, 1.9052, 1.4949, 1.9149, 1.5464, 1.6569, 1.724, 1.4884, 1.457, 0.8142, 1.486, 1.5107, 0.882, 0.4218, 1.1796, 0.953, 1.2893, 0.9381, 1.2923, 0.5007, 0.9853, 0.2185, 0.9555, 0.4927, -0.1144, 0.6736, 0.2179, 2.3578, 2.3574, 2.3569, 2.3567, 2.3565, 2.3564, 2.3559, 2.3555, 2.3551, 2.3548, 2.3526, 2.3525, 2.3524, 2.3521, 2.3515, 2.3503, 2.3501, 2.3498, 2.3498, 2.3497, 2.3496, 2.3491, 2.3489, 2.3485, 2.348, 2.3476, 2.3474, 2.347, 2.3469, 2.3468, 2.2146, 2.2856, 2.0271, 2.0919, 1.9863, 1.688, 2.0073, 1.8488, 1.0994, 1.243, 1.2893, 1.7237, 1.178, 1.2852, 1.041, 1.0114, 0.5398, 0.7171, 0.3685, 0.0478, 0.2012, 0.4428, 0.7442, 1.3661, 0.1655, 0.1563, 0.0372, 0.5909, 0.3546, 2.406, 2.4057, 2.4052, 2.4049, 2.4046, 2.4028, 2.4018, 2.3997, 2.3995, 2.3994, 2.3992, 2.399, 2.3989, 2.3986, 2.3974, 2.3969, 2.3968, 2.3964, 2.396, 2.3958, 2.3954, 2.3952, 2.3949, 2.3947, 2.3941, 2.3939, 2.3938, 2.3927, 2.3922, 2.392, 2.2769, 2.1589, 2.0597, 2.2737, 1.9176, 1.8094, 1.992, 1.6612, 1.8635, 2.0988, 1.904, 2.1176, 1.6296, 1.9486, 1.6665, 1.1524, 1.3934, 1.413, 1.598, 1.2932, 1.0451, 1.3033, 1.383, 0.9399, 1.4603, 1.2477, 1.3442, 1.1094, 1.2232, 0.6229, 0.855, 1.0135, 0.5396, 0.2684, -0.2359, 0.425, 1.1401, 0.774, 2.5852, 2.5834, 2.583, 2.5823, 2.5818, 2.5815, 2.581, 2.5799, 2.5799, 2.5798, 2.5788, 2.5787, 2.5779, 2.5778, 2.5773, 2.5771, 2.5771, 2.5761, 2.5759, 2.5751, 2.5745, 2.5744, 2.5741, 2.5737, 2.5734, 2.5734, 2.5731, 2.5728, 2.5727, 2.5726, 2.5111, 2.4297, 2.443, 2.4198, 2.4072, 2.4475, 2.1666, 2.249, 2.0119, 1.4306, 1.9169, 1.8668, 1.2646, 1.366, 1.0438, 1.652, 1.15, 1.4399, 1.1196, 1.3583, 0.4076, 0.5416, 0.3463, 0.7543, 1.0836, 0.7286, 0.9135, 0.6216, 0.1726, 0.2063, -0.9187, 0.5175, -0.5482, 2.8271, 2.8266, 2.8266, 2.8265, 2.8264, 2.8258, 2.8256, 2.8245, 2.8241, 2.8234, 2.8228, 2.8226, 2.8214, 2.8212, 2.8205, 2.8204, 2.8196, 2.8189, 2.8174, 2.8173, 2.8169, 2.8165, 2.8156, 2.8156, 2.8153, 2.8148, 2.8148, 2.8142, 2.8141, 2.8139, 2.6887, 2.5579, 2.4906, 2.4549, 2.5395, 2.6069, 2.2128, 2.4114, 2.0114, 2.0011, 1.8287, 2.4541, 1.0908, 1.2378, 1.8618, 1.5235, 1.0184, 1.7236, 0.121, 1.071, 1.2126, 0.7041, 0.544, 1.2193, 1.4624, 0.7917, 0.7786, 3.2615, 3.2615, 3.261, 3.2603, 3.2598, 3.2594, 3.259, 3.2589, 3.2589, 3.2585, 3.2578, 3.2575, 3.2572, 3.2569, 3.2563, 3.2559, 3.2556, 3.2555, 3.2553, 3.2553, 3.2553, 3.2551, 3.255, 3.2548, 3.2548, 3.2546, 3.2545, 3.2545, 3.2544, 3.2541, 2.7825, 2.9434, 3.146, 2.8292, 2.328, 1.9794, 1.6919, 1.5613, 1.9342, 1.5966, 1.3239, 1.6075, -0.4163, 1.6478, 0.6147, 2.225, 2.3251, 3.2625, 3.2621, 3.2617, 3.2617, 3.2615, 3.2614, 3.2613, 3.2611, 3.2603, 3.2598, 3.2597, 3.2597, 3.2596, 3.259, 3.2589, 3.2589, 3.2586, 3.2585, 3.2581, 3.2578, 3.2574, 3.257, 3.2568, 3.2568, 3.2561, 3.2559, 3.2558, 3.2556, 3.2553, 3.2548, 3.1064, 3.1169, 3.1089, 3.171, 2.0667, 2.5168, 1.5693, 2.8798, 1.0614, 1.6971, 1.3072, 2.4208, 2.4166, 1.7308, 1.9785, 1.2702, -0.0836, 1.8186, 0.8585, 1.4935, 1.1454, 1.4716, 3.6694, 3.6688, 3.6686, 3.6681, 3.668, 3.6679, 3.6675, 3.6673, 3.6669, 3.6665, 3.6664, 3.6663, 3.6662, 3.665, 3.6647, 3.6647, 3.6644, 3.6642, 3.6641, 3.6634, 3.6631, 3.663, 3.6625, 3.6625, 3.6625, 3.662, 3.6614, 3.6611, 3.6608, 3.6608, 3.3019, 3.3267, 2.5677, 3.2117, 1.8249, 2.574, 0.8554, 1.8069, 1.3555]}, \"token.table\": {\"Topic\": [7, 5, 9, 9, 4, 9, 1, 2, 3, 4, 7, 1, 3, 5, 7, 8, 1, 3, 4, 6, 8, 3, 4, 3, 8, 6, 8, 1, 2, 3, 1, 2, 3, 2, 4, 9, 7, 7, 3, 8, 9, 1, 1, 2, 1, 2, 3, 8, 9, 9, 2, 1, 2, 3, 5, 6, 7, 10, 3, 6, 7, 8, 7, 9, 3, 3, 6, 1, 2, 2, 1, 2, 4, 5, 8, 2, 3, 4, 5, 7, 9, 7, 1, 2, 10, 5, 1, 2, 4, 1, 3, 4, 5, 6, 7, 9, 10, 1, 2, 10, 9, 1, 10, 1, 6, 1, 4, 4, 1, 2, 3, 8, 9, 1, 1, 5, 6, 7, 4, 2, 2, 3, 4, 8, 4, 3, 3, 1, 9, 9, 8, 7, 7, 1, 2, 3, 4, 5, 6, 7, 10, 10, 8, 1, 2, 4, 5, 6, 7, 4, 5, 7, 7, 8, 6, 2, 3, 7, 2, 4, 10, 5, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 4, 10, 7, 5, 9, 4, 5, 7, 8, 9, 1, 2, 4, 5, 7, 1, 2, 5, 6, 8, 3, 4, 8, 9, 1, 4, 5, 6, 7, 2, 6, 5, 9, 6, 1, 2, 3, 4, 5, 6, 8, 9, 6, 7, 9, 1, 3, 4, 5, 6, 7, 9, 1, 2, 3, 9, 1, 3, 8, 2, 5, 8, 8, 1, 2, 3, 4, 7, 9, 8, 7, 7, 1, 1, 3, 10, 8, 1, 2, 3, 4, 5, 6, 8, 7, 1, 4, 5, 6, 7, 10, 2, 8, 8, 1, 2, 6, 3, 1, 3, 4, 7, 9, 1, 2, 3, 4, 5, 6, 7, 7, 6, 3, 1, 2, 3, 4, 5, 6, 2, 5, 5, 2, 5, 5, 1, 2, 8, 5, 8, 1, 1, 3, 4, 7, 8, 9, 3, 6, 1, 1, 3, 4, 5, 7, 10, 1, 2, 4, 5, 6, 7, 10, 10, 1, 4, 5, 8, 9, 10, 8, 9, 10, 1, 7, 5, 9, 8, 9, 2, 6, 4, 5, 1, 2, 3, 4, 6, 5, 9, 1, 2, 5, 5, 3, 6, 1, 9, 5, 6, 4, 1, 2, 4, 5, 1, 2, 6, 6, 2, 5, 4, 6, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 6, 1, 2, 3, 4, 8, 3, 1, 2, 6, 2, 10, 6, 6, 6, 3, 1, 2, 3, 4, 8, 9, 5, 6, 8, 10, 9, 10, 1, 2, 3, 5, 6, 7, 9, 2, 7, 1, 10, 10, 1, 4, 5, 1, 7, 4, 5, 8, 3, 6, 10, 7, 10, 3, 5, 6, 1, 4, 6, 3, 1, 2, 1, 1, 10, 1, 4, 1, 2, 5, 7, 8, 4, 4, 7, 1, 4, 5, 6, 2, 4, 5, 6, 8, 10, 10, 2, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 6, 1, 2, 4, 5, 6, 8, 3, 1, 2, 4, 7, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 9, 4, 1, 3, 4, 6, 7, 8, 5, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 2, 7, 9, 2, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 6, 9, 1, 5, 2, 10, 9, 10, 10, 6, 3, 8, 1, 2, 3, 4, 5, 6, 7, 10, 5, 2, 4, 5, 10, 1, 2, 1, 2, 8, 5, 4, 5, 9, 1, 2, 4, 5, 10, 5, 8, 8, 1, 8, 1, 4, 3, 4, 2, 1, 4, 1, 2, 3, 4, 7, 9, 9, 8, 1, 2, 4, 5, 7, 8, 10, 2, 7, 8, 1, 2, 3, 6, 7, 10, 6, 1, 2, 3, 4, 5, 7, 9, 1, 3, 10, 3, 7, 10, 1, 3, 4, 5, 10, 9, 1, 2, 3, 4, 7, 8, 9, 7, 5, 7, 1, 4, 6, 9, 4, 2, 7, 8, 4, 6, 3, 10, 6, 5, 1, 2, 3, 6, 10, 1, 4, 5, 6, 7, 4, 1, 4, 6, 1, 4, 6, 1, 2, 3, 10, 3, 1, 2, 3, 10, 1, 2, 10, 2, 3, 5, 6, 7, 8, 4, 10, 3, 4, 9, 6, 6, 7, 8, 2, 5, 2, 2, 1, 1, 2, 3, 5, 6, 10, 3, 2, 3, 5, 5, 7, 1, 3, 4, 5, 6, 7, 9, 2, 3, 1, 1, 2, 3, 4, 8, 3, 1, 2, 3, 4, 5, 7, 4, 3, 7, 1, 2, 5, 1, 3, 5, 1, 1, 4, 1, 7, 1, 3, 5, 7, 9, 1, 3, 4, 8, 8, 8, 1, 5, 1, 2, 3, 4, 6, 7, 8, 9, 8, 9, 3, 1, 8, 6, 9, 9, 4, 6, 8, 4, 7, 8, 5, 9, 1, 8, 1, 2, 4, 10, 4, 4, 1, 2, 5, 6, 7, 4, 1, 2, 3, 4, 5, 8, 1, 2, 3, 2, 4, 2, 8, 8, 7, 3, 1, 2, 8, 9, 1, 4, 6, 1, 3, 4, 7, 8, 9, 6, 9, 10, 3, 7, 6, 5, 7, 3, 10, 1, 2, 5, 1, 3, 2, 10, 5, 1, 4, 8, 1, 3, 8, 2, 9, 4, 1, 2, 4, 5, 6, 7, 1, 3, 1, 4, 10, 6, 6, 5, 5, 7, 8, 1, 4, 5, 8, 9, 1, 5, 1, 5, 9, 2, 6, 5, 6, 2, 7, 2, 1, 2, 3, 4, 6, 8, 9, 1, 2, 4, 6, 7, 1, 2, 1, 3, 4, 7, 8, 6, 7, 9, 10, 5, 10, 10, 4, 5, 9, 1, 4, 6, 3, 10, 6, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 9, 5, 8, 7, 7, 8, 3, 6, 1, 2, 3, 4, 5, 6, 7, 9, 2, 5, 10, 1, 2, 4, 5, 8, 2, 4, 6, 7, 10, 7, 7, 9, 1, 2, 4, 5, 6, 7, 4, 5, 6, 7, 8, 9, 4, 2, 3, 4, 7, 1, 2, 3, 4, 5, 5, 6, 10, 5, 7, 1, 1, 1, 2, 6, 7, 9, 4, 7, 8, 9, 10, 1, 3, 8], \"Freq\": [0.9987973276678916, 0.9962984214540422, 0.9971707042681563, 0.9968835578199285, 0.9964212965568517, 0.992418283448146, 0.22218820259079755, 0.5552792945986885, 0.012619983968152011, 0.14570345126866413, 0.06424719111059206, 0.010047436245343513, 0.7579534717581012, 0.22418342122422713, 0.0075355771840076346, 0.9924000988136448, 0.3499885687356326, 0.06652675273487232, 0.5307677881238726, 0.0216935063265888, 0.030370908857224318, 0.9981464208864237, 0.9979662046705748, 0.9991012851120034, 0.9926801355411742, 0.8369993404535975, 0.15722639544432218, 0.8765388819092752, 0.06478190831607011, 0.05817150950830786, 0.7463394808541676, 0.2529713602102332, 0.9982232457098692, 0.989909372035001, 0.9314309547409867, 0.06774043307207175, 0.9975672406389208, 0.9895635651116255, 0.9988339655380118, 0.9971620148035126, 0.9915300258219958, 0.9933146853761948, 0.9570132141525303, 0.041297005488758344, 0.2110484394421597, 0.4974494421684577, 0.204309592319188, 0.07075789479120304, 0.016234495341704593, 0.9947842491770644, 0.9965140344544097, 0.20862375381775913, 0.3175570429947536, 0.005281614020702763, 0.09407874974376797, 0.2310706134057459, 0.12873934175462984, 0.014194337680638675, 0.12711383643096788, 0.6571139001939865, 0.14004066725445616, 0.07325204133310013, 0.9910459352515602, 0.9895241738261393, 0.9898887672754209, 0.13085693929407294, 0.8678894062003956, 0.9254872006133051, 0.07399480004903514, 0.9957777258934903, 0.5534748666547997, 0.2731655303772613, 0.11974379413797757, 0.05306827240205825, 0.0006803624666930544, 0.20301876586741166, 0.007113865111257013, 0.19590490075615466, 0.387979258760094, 0.08646082212143139, 0.11984126610502198, 0.9967405095511459, 0.22389279089220726, 0.7756993595955677, 0.9994950022233297, 0.9912709347643711, 0.4147747871037306, 0.5097465841508465, 0.07494373100316627, 0.2553168590720728, 0.0521511880059497, 0.10782178133745429, 0.33146399247953306, 0.007038810651109776, 0.11486059198856408, 0.09022475470967986, 0.041273026090598235, 0.20418041972196566, 0.7943276973699696, 0.9951543963766285, 0.9890190622754452, 0.9946447336832687, 0.9960911309004772, 0.9511138553478241, 0.04860664730368714, 0.9936276805924155, 0.9883210776770304, 0.9923257683567492, 0.2053597656619905, 0.3248037109960054, 0.002095507812877454, 0.39290771491452264, 0.07439052735714963, 0.9981467199480599, 0.11712984666132001, 0.7799629095597725, 0.10155767051559537, 0.0013541022735412717, 0.9937388774924834, 0.9987980049415828, 0.06073313163156611, 0.8204300237948404, 0.07778102822990045, 0.04048875442104407, 0.9987004669003229, 0.9941731246604825, 0.9912338402322105, 0.9996424140319894, 0.9863604026522138, 0.9926478184170039, 0.9988664213493879, 0.998190319705305, 0.9952924852848956, 0.1170654351211901, 0.1504722582029324, 0.034680812097571435, 0.05619707103157493, 0.2560717921816601, 0.000990880345644898, 0.05237510398408747, 0.33208647012613296, 0.9953668128249031, 0.9933269397434472, 0.0006450003448362524, 0.0006450003448362524, 0.2599351389690097, 0.3699076977635908, 0.23800512724457715, 0.1306125698293411, 0.3941746516560862, 0.6044812493384492, 0.9810113651128269, 0.9995532018547217, 0.99822552830764, 0.9960217344094824, 0.9921490530987358, 0.9975158803325784, 0.9965930289578945, 0.9929578560320371, 0.9935572268294973, 0.989940052753997, 0.9855273560243124, 0.987096421249036, 0.23054758816547782, 0.5061323796004908, 0.0069700433631423525, 0.11366532253739837, 0.06326654745006136, 0.0793512629034668, 0.26179847599852224, 0.2755052024905915, 0.049686883533750954, 0.07298831857026865, 0.30600266893544553, 0.03392414806787134, 0.2897296678474015, 0.7092582268904388, 0.9831148762511909, 0.9893376594909375, 0.996829270504489, 0.2277037024446716, 0.23809018711758648, 0.33156854917382006, 0.11904509355879324, 0.08309187738331876, 0.9965651442356259, 0.9996955523031795, 0.7669101702610844, 0.13270131035978316, 0.0999568311800964, 0.08607830104580551, 0.59509902357629, 0.2483027914782851, 0.009932111659131404, 0.06042034592638271, 0.9995479655137275, 0.9884361589699998, 0.9926322941235219, 0.9923294845117913, 0.35641642577997196, 0.058171592808648274, 0.1772848542739757, 0.3933507704203836, 0.01385037924015435, 0.9922816271905991, 0.9999332523697653, 0.9903090591552579, 0.9961464478357349, 0.9904329245378458, 0.320569554462823, 0.22509306261017717, 0.005092079565474444, 0.28399916485623383, 0.008679681077513258, 0.0435141344685998, 0.002546039782737222, 0.11040554330596865, 0.9285673814004812, 0.07083385017618095, 0.9945720710022873, 0.20758654513525052, 0.15523180487415328, 0.014135779870496253, 0.27302997046162203, 0.16020550519895752, 0.0060207951300261815, 0.1835033646151458, 0.15520357284120725, 0.545925854119771, 0.29195637128870455, 0.007054707856418512, 0.997091626630723, 0.9912925341477954, 0.9971103487226943, 0.8392950075659296, 0.15887889032112248, 0.9895551831777578, 0.9966859012926295, 0.3768006615370053, 0.20182443296085295, 0.3346767546575612, 0.04582710748423038, 0.009720901587564019, 0.031014305065085204, 0.9895529105347071, 0.9959794345886973, 0.9951099254426568, 0.9933496309144353, 0.15943766626515105, 0.8402111936512722, 0.9964189933433651, 0.9939447561337433, 0.17689291116177622, 0.496593056251498, 0.07463587946028433, 0.059551987810830535, 0.09461713852839193, 0.0926581915609304, 0.004897367418653827, 0.9854930845134777, 0.0014185462960089523, 0.061706763876389424, 0.3830074999224171, 0.20001502773726226, 0.2553383332816114, 0.09858896757262219, 0.9945484146416697, 0.9947475411617986, 0.9973980294500728, 0.19107119436444606, 0.24388762207494336, 0.5638930370267798, 0.9965430886935637, 0.05891948460843256, 0.5520674996187379, 0.089589901253918, 0.13236706131209508, 0.1662659428676316, 0.5303495025634882, 0.04937248326039341, 0.0022258086715751125, 0.13668488705899895, 0.16784620846105053, 0.11331389600746028, 0.0002023462428704648, 0.9838822965218632, 0.9933462075130955, 0.9960832968942174, 0.11980750876063283, 0.2210766732095742, 0.02739247890832021, 0.12119096729135606, 0.19534434453812188, 0.3151518532987547, 0.9931227606480478, 0.9856085469356389, 0.9938769857468703, 0.9150029088468004, 0.07918294403481926, 0.9789347816954865, 0.07300545359373402, 0.7821047204439839, 0.14398297792097542, 0.9894080358637112, 0.9950098412195353, 0.996458470730535, 0.36500146729751104, 0.32455275588195576, 0.10401097221142795, 0.20031742796275012, 0.0033707259512962763, 0.0019261291150264436, 0.9898639717836112, 0.994859495515817, 0.9926512357708891, 0.3837574162818109, 0.13501787010136967, 0.02342581342452786, 0.18570281187443904, 0.2713135118440772, 0.9988951813040673, 0.09809689618996928, 0.04229716916980433, 0.19375357108168062, 0.47421633896146015, 0.08963746235600842, 0.10200125026718199, 0.9993571857953311, 0.9983461748766764, 0.11470795555939947, 0.12323642809169683, 0.345403137558043, 0.20766830616144066, 0.2085211534146704, 0.9965433653440189, 0.08767409933857484, 0.908622484054321, 0.9920932535561946, 0.991095016577008, 0.9857485945519583, 0.9860831010369165, 0.9957700162983666, 0.13672760768379, 0.8627983519356403, 0.9989533506524125, 0.9915465746915806, 0.991972331288385, 0.9824189671055823, 0.10192840929971099, 0.2588658013960914, 0.18525083912407792, 0.37050167824815583, 0.08251347419500414, 0.9982008758632507, 0.9979335481019019, 0.013483718703403853, 0.4362732096034669, 0.5498360849054682, 0.9905683987444335, 0.12232614521338164, 0.8706743276952458, 0.9946646743476049, 0.9899924653673502, 0.9939038863639554, 0.9915187571875204, 0.984374087721964, 0.45452162030186727, 0.16554594794480854, 0.30732333409401486, 0.07255666232341734, 0.7223701303207741, 0.27701900410466385, 0.9971232170141145, 0.9928204391189457, 0.9947831653862867, 0.9854747866502478, 0.9966162994895221, 0.9883687129474614, 0.996497378463218, 0.49209754586505056, 0.047905193513155725, 0.19039106484413787, 0.09923218656296542, 0.07110927162109053, 0.030101142799002983, 0.06677855658251283, 0.0014435716795258978, 0.0010158467374441504, 0.8779693125783821, 0.12058855618546452, 0.24440512537031572, 0.4931941991777672, 0.018083787303184797, 0.061375278119899915, 0.18248185369577385, 0.9940787453777349, 0.9945979484732427, 0.9992249690604161, 0.9915423190921883, 0.9904595951940047, 0.9960301433661064, 0.9967615439858456, 0.9902504134074404, 0.9983837792883731, 0.9977965340866173, 0.231195319810564, 0.05053071361129093, 0.13844031126381076, 0.13221049725693929, 0.2768806225276215, 0.17028158285448725, 0.9926218659376879, 0.7139461029263056, 0.2654874955605357, 0.01793834429463079, 0.854941974441525, 0.14369992439679283, 0.16554289771622843, 0.2146459601306073, 0.3016559469495718, 0.0673367728874707, 0.045264386525306906, 0.2039296566069481, 0.0015994482871133182, 0.3074331881753786, 0.6876794998659785, 0.9948813140382308, 0.991208163917544, 0.9947244054531038, 0.8630805918712606, 0.01909194865404087, 0.11776827023008907, 0.9981752488209733, 0.9988984872689656, 0.7180868952062338, 0.2817169908141339, 0.9901802919970143, 0.9972895657345328, 0.9971631509076796, 0.9926385330620672, 0.9923400405063177, 0.9989330612722483, 0.24496076894637733, 0.45949899078167233, 0.29553331479337136, 0.36733354959525905, 0.11836303264736124, 0.512906474805232, 0.9950128565505763, 0.9980525795357735, 0.9992098079868739, 0.9998005914322733, 0.9978648866191595, 0.99636065611765, 0.9938428266473531, 0.0060345430856681885, 0.3183614856782305, 0.4403340050874558, 0.01761336020349823, 0.19903097029953, 0.024658704284897522, 0.9990526208908699, 0.8656663841654374, 0.13262584745527484, 0.5121825887018822, 0.267983041832247, 0.09312410703670584, 0.12662198726573673, 0.29402119084541023, 0.044504448242109244, 0.3531172614619815, 0.10578926221484984, 0.045234029360832345, 0.15831910276291322, 0.9959455522401268, 0.22219501524661536, 0.6320213767014837, 0.05760611506393732, 0.08723211709681937, 0.31610564154985943, 0.3861888022973461, 0.1553266257173899, 0.11157451967199497, 0.018218962091851382, 0.00013298512475803928, 0.0018617917466125502, 0.010638809980643144, 0.9863301782598243, 0.46637092725051243, 0.2574808341640853, 0.08916651455487778, 0.16606010997158419, 0.008766370812979558, 0.012272919138171379, 0.9986976577640219, 0.4174490294548057, 0.11921380937315124, 0.3431912694075566, 0.12001659596825663, 0.181174415567643, 0.4051321871006571, 0.1113240384813228, 0.09822709277763778, 0.1543984376845536, 0.018190202366229216, 0.030559539975265084, 0.0008731297135790025, 0.3537012881827423, 0.19260252332218153, 0.4532245251410443, 0.14326098773393942, 0.1212208357748718, 0.0055100379897669, 0.1622760207966644, 0.28500941601970753, 0.1065274011354934, 0.1761051357513735, 0.22104120280002182, 0.12071044408228142, 0.6545014338227596, 0.0031353362099293875, 0.9894113070323152, 0.786695483892696, 0.07527657890006338, 0.11062658660156066, 0.026670318310504638, 0.000631250137526737, 0.00015781253438168426, 0.9927677053844775, 0.9931676620502554, 0.04641563078734788, 0.43474442301812966, 0.02803320275275466, 0.10523940049804618, 0.051470798496861016, 0.2228869399194428, 0.06525761952280594, 0.04595607008648305, 0.999753579953654, 0.9981056879162022, 0.13023950339379572, 0.7141320420988664, 0.15558813157111165, 0.9942448684038704, 0.16478152415909184, 0.4769991488815816, 0.032689452161115386, 0.06404464096871586, 0.17245353844180258, 0.08872851300874175, 0.9926056256197809, 0.6221999938308048, 0.29826941321830225, 0.06098693030050202, 0.005998714455787084, 0.012330690825784562, 0.9964983192972152, 0.9783113997890399, 0.02163010004139747, 0.9873772303926006, 0.9950451457499608, 0.6783592178962276, 0.31436158878117865, 0.9922567221472739, 0.9938044912080575, 0.10261440918711433, 0.8893248796216575, 0.2277407448518161, 0.3316714369893984, 0.3191160513620394, 0.04708269610259598, 0.03627111403459246, 0.00034876071187108133, 0.008370257084905953, 0.029295899797170833, 0.9949551329287419, 0.992953661431558, 0.9910317552112435, 0.3061088648614328, 0.6918414228949146, 0.07115610757523619, 0.927714534612985, 0.1249749057407686, 0.8080569247896271, 0.0667674153957531, 0.9882774428574292, 0.2748487327838883, 0.2946220229122256, 0.4290803957849192, 0.18116437189825207, 0.3938500172952843, 0.10750413277478695, 0.3135537205931286, 0.0036498316682798035, 0.7337313372559705, 0.2626939355607796, 0.9878178450621005, 0.9303854468489192, 0.06812445740525559, 0.9684955750194494, 0.031130214911339445, 0.9915045221223217, 0.9882895028351327, 0.9965358508013377, 0.9721977250930022, 0.02574046929981472, 0.316657556319829, 0.46860881802146326, 0.02606463248166719, 0.1347596955967048, 0.05379296490897271, 0.9878606495179559, 0.9972243384451153, 0.9908899565508584, 0.08663182504608834, 0.17746034749925363, 0.17086553728813272, 0.36271456161165017, 0.1726641218911657, 0.015287969125780296, 0.014388676824263808, 0.9930718410214604, 0.9987308832051999, 0.9980951035198203, 0.08678279787033462, 0.1823773875244263, 0.5567450263373775, 0.1562090361666023, 0.0018691679541302842, 0.016021439606831007, 0.9902297477424692, 0.24964617180897886, 0.10210309439117228, 0.3238283127741469, 0.0005474696750196905, 0.09827080666603444, 0.08431032995303234, 0.14124717615508015, 0.09501914670766896, 0.8416819476883022, 0.06275955986247271, 0.9970154525945526, 0.9934862991805041, 0.9978168948421299, 0.8097281358808786, 0.12591466227812706, 0.0038742973008654476, 0.0005534710429807783, 0.06005160816341444, 0.9949821442624698, 0.22879436032497197, 0.1381399911396057, 0.21152686143252125, 0.08094140105836273, 0.034534997784901426, 0.19857623726318321, 0.1068426493970388, 0.9963688789072229, 0.9829009906713999, 0.9885919376175502, 0.9449509025789219, 0.021181962946974588, 0.032949720139738244, 0.9953861560335656, 0.9993670539942309, 0.19632821929424815, 0.8008944818828854, 0.9947508643272548, 0.9996782461435556, 0.997392329394845, 0.996454244558514, 0.98850763904503, 0.995185565241388, 0.9953451333934015, 0.013404057329646992, 0.31566555011318664, 0.5361622931858797, 0.06836069238119966, 0.06635008378175261, 0.10765747805486833, 0.19907465528394144, 0.32821124088260345, 0.2669172022820215, 0.0979656856265712, 0.9865440714261187, 0.47647488860247733, 0.20457700978405405, 0.31830352640522147, 0.9887085699628698, 0.010096494473902226, 0.000747888479548313, 0.15935297023211265, 0.3865785018593844, 0.2980490739526551, 0.15541832899181357, 0.9922897609506693, 0.058269888596877484, 0.45707808717550646, 0.4548078317756281, 0.029513320198418465, 0.3307000232730706, 0.3349671203475618, 0.3349671203475618, 0.2952131223345682, 0.02647291586152378, 0.19493692588940237, 0.017648610574349185, 0.44201747393029095, 0.023264077575278472, 0.9959829781823226, 0.9972912870238488, 0.33623030728135134, 0.2337210672565491, 0.4284886233036733, 0.9869050893643726, 0.3445880872665732, 0.03575914113143684, 0.6192833077762471, 0.9942316608668056, 0.9921163303075686, 0.9909678050010162, 0.9909989263010655, 0.9960366094552624, 0.3196758083057435, 0.4626765306358741, 0.029061437118703955, 0.10332955419983629, 0.061351922806152794, 0.023525925286569868, 0.9977972376979506, 0.0006760240007776011, 0.8517902409797773, 0.14669720816873943, 0.9982993842921501, 0.9929791663771725, 0.19654936617095162, 0.08653116749664537, 0.0004120531785554542, 0.35889831852180054, 0.006592850856887267, 0.04862227506954359, 0.30162292670259244, 0.9963950112701118, 0.9955612523948029, 0.9975868550622545, 0.18904866153116043, 0.08296380110360278, 0.05304243021377882, 0.6011475424228266, 0.07344336491138606, 0.9971496397257412, 0.3386827927710594, 0.3985820635586682, 0.12035834784426078, 0.051782079886484284, 0.0817317152802887, 0.008676997170167637, 0.9940251310019332, 0.45851600937692666, 0.5406916058626616, 0.29398407664401516, 0.12486949074846129, 0.5801023585952139, 0.13863516477433627, 0.20085724660218798, 0.6604273597517595, 0.9980835294079529, 0.9110645304595276, 0.08779349111700903, 0.9940364266240354, 0.9958384898463193, 0.36927299984759254, 0.40629170404023485, 0.02513615716784355, 0.06306890343931655, 0.1361922697457705, 0.44646191232309723, 0.5532088638963095, 0.9954995780032718, 0.99558389925009, 0.9930924284221256, 0.9953040301589218, 0.9099918419475569, 0.08975362370255693, 0.4461388056317438, 0.05011244184867758, 0.2819129427176011, 0.11565659188414404, 0.025421708749815367, 0.02038609870991584, 0.02525926971627022, 0.03516805076252413, 0.9910930662029648, 0.9947558258147765, 0.9972111630177625, 0.9941607675563019, 0.996361025478328, 0.9853001071849293, 0.9957268468473172, 0.9884750014361983, 0.23916737674900368, 0.10988771364143413, 0.649630307115537, 0.9949198251084785, 0.9932617404265236, 0.995968891277867, 0.9992686774283247, 0.9908409087960758, 0.2712205798221404, 0.7256031096540378, 0.12137771762576934, 0.3429531484593885, 0.511578568248209, 0.023623851081525576, 0.9981779930417329, 0.9990052797462117, 0.1704886981413558, 0.28387493916213746, 0.21183169576987185, 0.21408304712588017, 0.11952629017353156, 0.996391899269119, 0.10012314160144899, 0.7356874317671687, 0.06790960908620018, 0.04440243671020781, 0.047014344751984745, 0.00522381608355386, 0.3268009333002426, 0.10635533332256417, 0.5656169999427276, 0.9952259641006419, 0.9875292780059497, 0.9985118085980959, 0.994443590972589, 0.9983239844414806, 0.9839087199095746, 0.997678745903135, 0.15399665918543937, 0.4173532647489444, 0.35486186681862114, 0.07365057613216666, 0.7768338832858945, 0.14923835741723174, 0.07376800936973432, 0.04616720674527021, 0.20811883675645618, 0.1494938123180178, 0.3686048411566812, 0.012457817693168153, 0.215446964811261, 0.9965203124455216, 0.9955993600723726, 0.993927113838826, 0.8481293990604181, 0.1514516784036461, 0.9932899966598463, 0.9816228732442372, 0.9957563132581724, 0.36545237445602125, 0.6337591810186697, 0.3249046524910853, 0.44450217152633426, 0.23046104203579132, 0.10838504616150235, 0.8911155468926867, 0.9898364325850914, 0.9953686478988526, 0.9897623938120723, 0.3101104756024127, 0.6897284715984696, 0.9905679205886873, 0.41331450981891305, 0.5859881272543701, 0.9954389407352955, 0.9938172441471889, 0.9888580913854944, 0.9922619743615614, 0.3821821430232049, 0.02511995306255807, 0.052632282607264526, 0.4449820256796001, 0.027512329544706456, 0.06698654150015484, 0.27168747012984656, 0.7279323179280728, 0.21289182050563332, 0.703468624279484, 0.08099145345323007, 0.9941663612233268, 0.9886392187932371, 0.9813349264131027, 0.7483652437631205, 0.11618455839244794, 0.12985332996803003, 0.8486482285907349, 0.03755323233750991, 0.06825368505138661, 0.001096444739781311, 0.0444060119611431, 0.386889829690077, 0.6128855715523095, 0.9810460664320904, 0.018607828446551768, 0.9974975243618739, 0.5113552711356193, 0.4870628592051861, 0.706012239995543, 0.2929065117544233, 0.794421158407269, 0.20379758475480594, 0.9895602863940884, 0.5093132458347234, 0.024345757449078555, 0.05648215728186225, 0.08861855711464595, 0.0740111026451988, 0.19087073840077587, 0.05648215728186225, 0.2098408393801524, 0.19616849007209713, 0.3418087327013814, 0.07192844635976896, 0.1789294409445492, 0.0886108827353077, 0.9062476643383743, 0.09168208174882787, 0.3633638469311343, 0.1463548827917069, 0.38102736726806447, 0.016822400320885847, 0.9864807877829952, 0.6889919978312491, 0.2764744959450235, 0.03401075148530051, 0.9966433268747091, 0.9941550772464852, 0.9965633878587357, 0.10912001054739781, 0.03680379053965488, 0.8535896683056798, 0.5850045813399257, 0.3277035917057976, 0.08681935233053405, 0.9975693782540135, 0.9942540450802375, 0.9927030176131022, 0.9979525310153081, 0.8710763125774887, 0.12878038508205397, 0.3046190404892887, 0.08854137773257939, 0.02370278678506011, 0.1472631204775025, 0.13778200576347846, 0.12952426068997364, 0.16377861062451213, 0.004740557357012023, 0.8765788033321193, 0.12190831039718217, 0.9996466241001227, 0.6602889987717543, 0.33699397032749284, 0.9947360101711411, 0.9967188459592738, 0.2927820786558136, 0.1504899884290882, 0.022251437977841838, 0.09896034258566501, 0.24798642062147416, 0.14024261567613472, 0.04684513258493018, 0.9942062664647304, 0.44480005027473646, 0.47666438136166933, 0.07803509653942746, 0.2545823880811055, 0.025188363485056375, 0.11604638891329544, 0.4147084130932496, 0.18891272613792282, 0.9860310381034271, 0.9909385011574654, 0.1690821284636863, 0.750180478011298, 0.07968238237943838, 0.9958690492662842, 0.7639523371996959, 0.2359116941418246, 0.32591321134277024, 0.20133336842713143, 0.051297582377027744, 0.17086337588739314, 0.1878340046437031, 0.06171137729567247, 0.17504319523576053, 0.23585632409701068, 0.09286329136920629, 0.43801888760873414, 0.001643598077331085, 0.05670413366792243, 0.9931008256462505, 0.07890321840033628, 0.6995073785106735, 0.053107935461764795, 0.1653932847237818, 0.5349429627197877, 0.21863539628013795, 0.20605071281727777, 0.0001878310964605996, 0.04000802354610772, 0.14734078321535926, 0.8482050493208521, 0.990146033688511, 0.9880032298655403, 0.9850145479610032, 0.9995264728764237, 0.9966127589490834, 0.9979243595441766, 0.1253914029778697, 0.8561206134351101, 0.018016006174981274, 0.9987765360318578, 0.12213955623885994, 0.13879495027143174, 0.26509835501843465, 0.47329078042558226, 0.9950087986372665, 0.20341934260314287, 0.4042637568189042, 0.3913891148819964], \"Term\": [\"ab\", \"addition\", \"adju\", \"adore\", \"ag\", \"ago\", \"al\", \"al\", \"al\", \"al\", \"al\", \"ale\", \"ale\", \"ale\", \"ale\", \"allow\", \"alway\", \"alway\", \"alway\", \"alway\", \"alway\", \"andal\", \"ankle\", \"appointed\", \"appreciate\", \"appropriate\", \"appropriate\", \"area\", \"area\", \"area\", \"arm\", \"arm\", \"arrived\", \"ary\", \"athletic\", \"athletic\", \"atile\", \"attracted\", \"aw\", \"awe\", \"awful\", \"awkward\", \"b\", \"b\", \"back\", \"back\", \"back\", \"back\", \"back\", \"beach\", \"beading\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautifully\", \"beautifully\", \"beautifully\", \"beautifully\", \"become\", \"beige\", \"bell\", \"belt\", \"belt\", \"big\", \"big\", \"billowy\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"blazer\", \"blou\", \"blou\", \"blue\", \"both\", \"bottom\", \"bottom\", \"bottom\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bra\", \"bra\", \"bright\", \"bring\", \"broad\", \"brown\", \"bu\", \"bu\", \"build\", \"bulk\", \"butt\", \"button\", \"button\", \"button\", \"button\", \"button\", \"c\", \"ca\", \"ca\", \"ca\", \"ca\", \"calve\", \"cami\", \"can\", \"can\", \"can\", \"can\", \"cardigan\", \"caught\", \"chance\", \"che\", \"cho\", \"clean\", \"clo\", \"coat\", \"cold\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"combination\", \"combo\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfy\", \"comfy\", \"complement\", \"compliment\", \"cool\", \"cooler\", \"coverage\", \"covered\", \"cozy\", \"cratchy\", \"crop\", \"crotch\", \"cu\", \"cular\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"dark\", \"dark\", \"darling\", \"date\", \"daughter\", \"day\", \"day\", \"day\", \"day\", \"day\", \"dd\", \"de\", \"denim\", \"denim\", \"denim\", \"detail\", \"detail\", \"detail\", \"detail\", \"detail\", \"di\", \"do\", \"dot\", \"double\", \"down\", \"down\", \"down\", \"down\", \"down\", \"draw\", \"dre\", \"drew\", \"dry\", \"du\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"ea\", \"ea\", \"econd\", \"ed\", \"ed\", \"ed\", \"ed\", \"ed\", \"ed\", \"ed\", \"ee\", \"ee\", \"ee\", \"ee\", \"eemed\", \"een\", \"ela\", \"embroidery\", \"embroidery\", \"eriou\", \"et\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"evening\", \"event\", \"everyone\", \"exchange\", \"excited\", \"excited\", \"expen\", \"ey\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"faded\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"falling\", \"fanta\", \"feeling\", \"figure\", \"figure\", \"figure\", \"finally\", \"fir\", \"fir\", \"fir\", \"fir\", \"fir\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"five\", \"flair\", \"flatter\", \"flattering\", \"flattering\", \"flattering\", \"flattering\", \"flattering\", \"flattering\", \"flim\", \"flip\", \"flop\", \"floral\", \"floral\", \"fre\", \"front\", \"front\", \"front\", \"fuller\", \"garment\", \"generally\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"giving\", \"glove\", \"gone\", \"got\", \"got\", \"got\", \"got\", \"got\", \"gray\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"green\", \"grey\", \"h\", \"h\", \"h\", \"h\", \"h\", \"hade\", \"hand\", \"hand\", \"hanger\", \"hapele\", \"happened\", \"hate\", \"head\", \"hed\", \"hed\", \"heer\", \"hemline\", \"hemmed\", \"her\", \"high\", \"high\", \"high\", \"high\", \"high\", \"highly\", \"hing\", \"hirt\", \"hirt\", \"hirt\", \"hoe\", \"holiday\", \"holiday\", \"home\", \"hone\", \"honey\", \"hopefully\", \"hopping\", \"hort\", \"hort\", \"hort\", \"hort\", \"houlder\", \"houlder\", \"hourgla\", \"hower\", \"howing\", \"hrink\", \"hu\", \"hug\", \"hung\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"i\", \"ic\", \"ic\", \"ide\", \"ide\", \"ide\", \"ide\", \"ide\", \"idea\", \"ider\", \"ign\", \"igned\", \"igner\", \"ilhouette\", \"ilk\", \"ilver\", \"ily\", \"immediately\", \"in\", \"in\", \"in\", \"in\", \"in\", \"in\", \"ine\", \"intere\", \"intere\", \"intere\", \"ion\", \"ion\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"itchy\", \"itchy\", \"ite\", \"ition\", \"ive\", \"ize\", \"ize\", \"ize\", \"izing\", \"jacket\", \"jean\", \"jean\", \"jer\", \"ju\", \"jump\", \"keeper\", \"kimono\", \"kin\", \"kirt\", \"kirt\", \"kirt\", \"knee\", \"knee\", \"knee\", \"knew\", \"l\", \"lace\", \"large\", \"larger\", \"lavender\", \"lb\", \"lb\", \"leeve\", \"leeve\", \"leeve\", \"leeve\", \"leeve\", \"leg\", \"legging\", \"legging\", \"length\", \"length\", \"length\", \"length\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"lighter\", \"lightweight\", \"lightweight\", \"lightweight\", \"lightweight\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"liner\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"local\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"looked\", \"looked\", \"looked\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"loved\", \"loved\", \"loved\", \"loved\", \"luck\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"machine\", \"mail\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"mall\", \"maller\", \"many\", \"many\", \"many\", \"match\", \"material\", \"material\", \"material\", \"material\", \"material\", \"material\", \"maxi\", \"me\", \"me\", \"me\", \"me\", \"me\", \"meant\", \"medium\", \"medium\", \"metallic\", \"mix\", \"mo\", \"mo\", \"money\", \"motif\", \"movement\", \"movement\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"muted\", \"nag\", \"natural\", \"navy\", \"navy\", \"neck\", \"neck\", \"neckline\", \"neckline\", \"neckline\", \"nervou\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"no\", \"normal\", \"normal\", \"normally\", \"normally\", \"noted\", \"nt\", \"nude\", \"nug\", \"nug\", \"o\", \"o\", \"o\", \"o\", \"o\", \"obviou\", \"occa\", \"ock\", \"oft\", \"oft\", \"oft\", \"oft\", \"oft\", \"oft\", \"oft\", \"ole\", \"olutely\", \"ome\", \"on\", \"on\", \"on\", \"on\", \"on\", \"on\", \"onally\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"online\", \"online\", \"online\", \"oon\", \"ophi\", \"orange\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"originally\", \"out\", \"out\", \"out\", \"out\", \"out\", \"out\", \"out\", \"outfit\", \"overly\", \"own\", \"p\", \"p\", \"p\", \"package\", \"pair\", \"paired\", \"paired\", \"panel\", \"pant\", \"party\", \"pay\", \"peach\", \"pear\", \"pencil\", \"per\", \"per\", \"per\", \"per\", \"per\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfection\", \"perfectly\", \"perfectly\", \"perfectly\", \"petite\", \"petite\", \"petite\", \"photo\", \"photo\", \"photo\", \"photo\", \"picked\", \"picture\", \"picture\", \"picture\", \"picture\", \"pictured\", \"pictured\", \"pictured\", \"piece\", \"piece\", \"piece\", \"piece\", \"piece\", \"piece\", \"pilcro\", \"pink\", \"plea\", \"plea\", \"plea\", \"plenty\", \"pocket\", \"pocket\", \"pocket\", \"polye\", \"poncho\", \"poor\", \"portion\", \"pound\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"previou\", \"price\", \"price\", \"price\", \"pring\", \"pro\", \"purcha\", \"purcha\", \"purcha\", \"purcha\", \"purcha\", \"purcha\", \"purcha\", \"purple\", \"quickly\", \"ran\", \"re\", \"re\", \"re\", \"re\", \"re\", \"reading\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"receive\", \"received\", \"received\", \"recommend\", \"recommend\", \"recommend\", \"red\", \"red\", \"red\", \"reference\", \"regular\", \"regular\", \"relaxed\", \"remind\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"review\", \"review\", \"ri\", \"ro\", \"rolled\", \"round\", \"run\", \"run\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"ta\", \"table\", \"tag\", \"tailored\", \"tand\", \"tandard\", \"tantial\", \"tantly\", \"taple\", \"taple\", \"taple\", \"tated\", \"tatement\", \"te\", \"tee\", \"terday\", \"texture\", \"texture\", \"the\", \"the\", \"the\", \"the\", \"them\", \"they\", \"thi\", \"thi\", \"thi\", \"thi\", \"thi\", \"thigh\", \"thin\", \"thin\", \"thin\", \"thin\", \"thin\", \"thin\", \"thought\", \"thought\", \"thought\", \"thread\", \"thrilled\", \"through\", \"throw\", \"tic\", \"ticated\", \"tice\", \"tie\", \"tie\", \"tie\", \"tie\", \"tight\", \"tight\", \"tight\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"ting\", \"tly\", \"tock\", \"today\", \"today\", \"tomach\", \"tomer\", \"ton\", \"tone\", \"tone\", \"top\", \"top\", \"top\", \"tore\", \"tore\", \"toward\", \"tran\", \"travel\", \"tretch\", \"tretch\", \"tretched\", \"tried\", \"tried\", \"trim\", \"tring\", \"trip\", \"trou\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"try\", \"try\", \"tunic\", \"tunic\", \"tunic\", \"turn\", \"turquoi\", \"turtleneck\", \"tyli\", \"tyli\", \"tyli\", \"u\", \"u\", \"u\", \"u\", \"u\", \"ual\", \"ual\", \"ually\", \"ually\", \"ub\", \"uit\", \"uit\", \"ummer\", \"ummer\", \"underneath\", \"underneath\", \"unu\", \"up\", \"up\", \"up\", \"up\", \"up\", \"up\", \"up\", \"uper\", \"uper\", \"uper\", \"uper\", \"uper\", \"v\", \"v\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"velvet\", \"ver\", \"ver\", \"ver\", \"very\", \"vibe\", \"vibrant\", \"wa\", \"wa\", \"wa\", \"wai\", \"wai\", \"wai\", \"wait\", \"walk\", \"walked\", \"wardrobe\", \"warm\", \"warm\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"weat\", \"weat\", \"weater\", \"weather\", \"weather\", \"web\", \"wedding\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"what\", \"white\", \"white\", \"white\", \"wi\", \"wi\", \"wi\", \"wi\", \"wi\", \"wim\", \"wingy\", \"winter\", \"winter\", \"winter\", \"wool\", \"wore\", \"wore\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worn\", \"worn\", \"worn\", \"worn\", \"worn\", \"worn\", \"worry\", \"worth\", \"worth\", \"worth\", \"worth\", \"would\", \"would\", \"would\", \"would\", \"would\", \"wrap\", \"wrap\", \"wri\", \"wrinkled\", \"write\", \"x\", \"xl\", \"xx\", \"y\", \"y\", \"y\", \"ye\", \"year\", \"year\", \"year\", \"year\", \"yellow\", \"zipper\", \"zipper\", \"zipper\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 3, 10, 8, 1, 6, 9, 5, 2, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el308830801681891689247050517\", ldavis_el308830801681891689247050517_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el308830801681891689247050517\", ldavis_el308830801681891689247050517_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el308830801681891689247050517\", ldavis_el308830801681891689247050517_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "6     -0.146363 -0.080212       1        1  29.036331\n",
       "2     -0.135239 -0.006553       2        1  16.365083\n",
       "9     -0.004485 -0.136106       3        1  12.486443\n",
       "7     -0.129214 -0.022651       4        1   9.458354\n",
       "0     -0.138856  0.119845       5        1   9.004510\n",
       "5     -0.141472  0.119119       6        1   7.537778\n",
       "8     -0.047026  0.059019       7        1   5.916363\n",
       "4      0.206433 -0.190527       8        1   3.827727\n",
       "1      0.223787 -0.183877       9        1   3.819927\n",
       "3      0.312434  0.321941      10        1   2.547484, topic_info=         Term          Freq         Total Category  logprob  loglift\n",
       "9         dre  13085.000000  13085.000000  Default  30.0000  30.0000\n",
       "105     color   7064.000000   7064.000000  Default  29.0000  29.0000\n",
       "478    weater   2964.000000   2964.000000  Default  28.0000  28.0000\n",
       "51        ize   9637.000000   9637.000000  Default  27.0000  27.0000\n",
       "67        top   8587.000000   8587.000000  Default  26.0000  26.0000\n",
       "..        ...           ...           ...      ...      ...      ...\n",
       "188     light    216.568224   1370.649506  Topic10  -4.4968   1.8249\n",
       "437  pictured    156.629839    468.702719  Topic10  -4.8208   2.5740\n",
       "26    ordered    216.540190   3613.558515  Topic10  -4.4969   0.8554\n",
       "584     photo    157.754900   1016.611110  Topic10  -4.8137   1.8069\n",
       "245      fall    139.314008   1409.894062  Topic10  -4.9380   1.3555\n",
       "\n",
       "[610 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "0         7  0.998797        ab\n",
       "1533      5  0.996298  addition\n",
       "88        9  0.997171      adju\n",
       "2168      9  0.996884     adore\n",
       "2390      4  0.996421        ag\n",
       "...     ...       ...       ...\n",
       "237       9  0.473291      year\n",
       "1470     10  0.995009    yellow\n",
       "74        1  0.203419    zipper\n",
       "74        3  0.404264    zipper\n",
       "74        8  0.391389    zipper\n",
       "\n",
       "[1031 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 3, 10, 8, 1, 6, 9, 5, 2, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "# feed the LDA model into the pyLDAvis instance\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, doc_term_matrix, dictionary)     \n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
